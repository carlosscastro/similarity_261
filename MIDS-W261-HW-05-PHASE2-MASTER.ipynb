{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW5\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  Carlos Castro   \n",
    "__Class:__ MIDS w261 (Section 2, e.g., Fall 2016 Group 1)     \n",
    "__Email:__  carlosscastro@iSchool.Berkeley.edu     \n",
    "__Week:__   5\n",
    "\n",
    "__Due Time:__ 2 Phases. \n",
    "\n",
    "* __HW5 Phase 1__ \n",
    "This can be done on a local machine (with a unit test on the cloud such as AltaScale's PaaS or on AWS) and is due Tuesday, Week 6 by 8AM (West coast time). It will primarily focus on building a unit/systems and for pairwise similarity calculations pipeline (for stripe documents)\n",
    "\n",
    "* __HW5 Phase 2__ \n",
    "This will require the AltaScale cluster and will be due Tuesday, Week 7 by 8AM (West coast time). \n",
    "The focus of  HW5 Phase 2  will be to scale up the unit/systems tests to the Google 5 gram corpus. This will be a group exercise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.13 | packaged by conda-forge | (default, May  2 2017, 12:48:11) \\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"TOC\"></a> \n",
    "\n",
    "1.  [HW Instructions](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW Problems](#3)   \n",
    "       \n",
    "    5.4.  [HW5.4](#5.4)    \n",
    "    5.5.  [HW5.5](#5.5)    \n",
    "    5.6.  [HW5.6](#5.6)    \n",
    "    5.7.  [HW5.7](#5.7)    \n",
    "    5.8.  [HW5.8](#5.8)    \n",
    "    5.9.  [HW5.9](#5.9)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# 1 Instructions\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "MIDS UC Berkeley, Machine Learning at Scale   \n",
    "DATSCIW261 ASSIGNMENT #5\n",
    "\n",
    "Version 2017-9-2 \n",
    "\n",
    "\n",
    "### IMPORTANT\n",
    "\n",
    "This homework must be completed in the cloud \n",
    "\n",
    "### === INSTRUCTIONS for SUBMISSIONS ===   \n",
    "Follow the instructions for submissions carefully.\n",
    "\n",
    "Each student has a `HW-<user>` repository for all assignments.   \n",
    "\n",
    "Click this link to enable you to create a github repo within the MIDS261 Classroom:   \n",
    "https://classroom.github.com/assignment-invitations/3b1d6c8e58351209f9dd865537111ff8   \n",
    "and follow the instructions to create a HW repo.\n",
    "\n",
    "Push the following to your HW github repo into the master branch:\n",
    "* Your local HW5 directory. Your repo file structure should look like this:\n",
    "\n",
    "```\n",
    "HW-<user>\n",
    "    --HW3\n",
    "       |__MIDS-W261-HW-03-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-03-<Student_id>.pdf\n",
    "       |__some other hw3 file\n",
    "    --HW4\n",
    "       |__MIDS-W261-HW-04-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-04-<Student_id>.pdf\n",
    "       |__some other hw4 file\n",
    "    etc..\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\">\n",
    "# 2 Useful References\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "* See async and live lectures for this week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\">\n",
    "# 3 HW Problems\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5.4\"></a> \n",
    "# PHASE 2\n",
    "----------\n",
    "\n",
    "# HW 5.4   \n",
    "## Full-scale experiment on Google N-gram data on the CLOUD\n",
    "__ Once you are happy with your test results __ proceed to generating  your results on the Google n-grams dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.0  <a name=\"5.4.0\"></a> Run systems tests on the CLOUD  (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Repeat HW5.3.0 (using the same small data sources that were used in HW5.3.0) on ** the cloud** (e.g., AltaScale / AWS/ SoftLayer/ Azure). Make sure all tests give correct results! Good luck out there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing buildStripes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import itertools\n",
    "import collections\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class MRbuildStripes(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_STRIPES\n",
    "  \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    #def mapper_init(self):\n",
    "    #    return self.start_time = time.time()\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "        words = splits[0].lower().split()\n",
    "        count = splits[1]\n",
    "\n",
    "        H = {}\n",
    "        for subset in itertools.combinations(sorted(set(words)), 2):\n",
    "            \n",
    "            # Process combinations in sorted order, i.e. \"hello\",\"tomorrow\"\n",
    "            if subset[0] not in H.keys():\n",
    "                H[subset[0]] = {}\n",
    "                H[subset[0]][subset[1]] = count \n",
    "            elif subset[1] not in H[subset[0]]:\n",
    "                H[subset[0]][subset[1]] = count\n",
    "            else:\n",
    "                H[subset[0]][subset[1]] += count\n",
    "\n",
    "            # Obtain combinations in reverse order, to consider them both ways\n",
    "            # TODO: Should refactor this and the block above, shameless copy-paste\n",
    "            if subset[1] not in H.keys():\n",
    "                H[subset[1]] = {}\n",
    "                H[subset[1]][subset[0]] = count \n",
    "            elif subset[0] not in H[subset[1]]:\n",
    "                H[subset[1]][subset[0]] = count\n",
    "            else:\n",
    "                H[subset[1]][subset[0]] += count\n",
    "        for key in H.keys():\n",
    "            #print \"%s\\t%s\" % (key, json.dumps(H[key]))\n",
    "            yield key, H[key]\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        \n",
    "        counter = {}\n",
    "\n",
    "        for value in values:\n",
    "            \n",
    "            for k, v in value.iteritems():\n",
    "                if k in counter:\n",
    "                    counter[k] += int(v)\n",
    "                else:\n",
    "                    counter[k] = int(v)\n",
    "        \n",
    "        yield key, counter\n",
    "        \n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "\n",
    "            MRStep(#mapper_init=self.mapper_init\n",
    "                   #,\n",
    "                   mapper=self.mapper\n",
    "                   ,\n",
    "                   reducer=self.reducer\n",
    "                  )\n",
    "            ]\n",
    "  #END SUDENT CODE531_STRIPES\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    MRbuildStripes.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing invertedIndex.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "\n",
    "class MRinvertedIndex(MRJob):\n",
    "    \n",
    "    #START SUDENT CODE531_INV_INDEX\n",
    "  \n",
    "    def mapper(self, _, line):\n",
    "        key, stripeJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        stripe = json.loads(stripeJson)\n",
    "        \n",
    "        for k, v in stripe.iteritems():\n",
    "            yield k, [key, len(stripe)]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "\n",
    "        table = {}\n",
    "        for value in values:\n",
    "            table[value[0]] = value[1]\n",
    "            \n",
    "        yield key, table\n",
    "        \n",
    "    #END SUDENT CODE531_INV_INDEX\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    MRinvertedIndex.run() \n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing similarity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class MRsimilarity(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_SIMILARITY\n",
    "\n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        key, valuesJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        values = json.loads(valuesJson)\n",
    "\n",
    "        for pair in itertools.combinations(sorted(set(values)), 2):\n",
    "            yield pair, [values[pair[0]], values[pair[1]]]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        intersection = 0\n",
    "        count1 = None\n",
    "        count2 = None\n",
    "        \n",
    "        cosine = 0.0\n",
    "        \n",
    "        # Iterate through the values\n",
    "        for value in values:\n",
    "            # Jaccard, get counts for the intersection, and for each set\n",
    "            intersection += 1\n",
    "            if count1 == None:\n",
    "                count1 = value[0]\n",
    "                count2 = value[1]\n",
    "        \n",
    "            # Cosine\n",
    "            a = 1 / math.sqrt(value[0])\n",
    "            b = 1 / math.sqrt(value[1])\n",
    "            cosine += a * b\n",
    "            \n",
    "        jaccard = float(intersection) / float(count1 + count2 - intersection)\n",
    "        \n",
    "        overlap_coefficient = float(intersection) / min(count1, count2)\n",
    "        \n",
    "        dice_coefficient = float(2 * intersection) / (count1 + count2)\n",
    "        \n",
    "        average = (cosine + jaccard + overlap_coefficient + dice_coefficient) / 4.0\n",
    "        \n",
    "        yield average, [key[0] + ' - ' + key[1], cosine, jaccard, overlap_coefficient, dice_coefficient]\n",
    "            \n",
    "    #END SUDENT CODE531_SIMILARITY\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    MRsimilarity.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "A BILL FOR ESTABLISHING RELIGIOUS\t59\t59\t54\n",
    "A Biography of General George\t92\t90\t74\n",
    "A Case Study in Government\t102\t102\t78\n",
    "A Case Study of Female\t447\t447\t327\n",
    "A Case Study of Limited\t55\t55\t43\n",
    "A Child's Christmas in Wales\t1099\t1061\t866\n",
    "A Circumstantial Narrative of the\t62\t62\t50\n",
    "A City by the Sea\t62\t60\t49\n",
    "A Collection of Fairy Tales\t123\t117\t80\n",
    "A Collection of Forms of\t116\t103\t82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing atlas-boon-systems-test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile atlas-boon-systems-test.txt\n",
    "atlas boon\t50\t50\t50\n",
    "boon cava dipped\t10\t10\t10\n",
    "atlas dipped\t15\t15\t15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build stripes for mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.nhaas.20170620.004317.534010\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004317.534010/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3756263282695696765.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0120\n",
      "  Submitted application application_1497906899862_0120\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0120/\n",
      "  Running job: job_1497906899862_0120\n",
      "  Job job_1497906899862_0120 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0120 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004317.534010/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2406\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1098\n",
      "\t\tFILE: Number of bytes written=400003\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1007\n",
      "\t\tHDFS: Number of bytes written=2406\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10618368\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9809920\n",
      "\t\tTotal time spent by all map tasks (ms)=6913\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20739\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3832\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=19160\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6913\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3832\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2440\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=82\n",
      "\t\tInput split bytes=444\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=3359\n",
      "\t\tMap output materialized bytes=1076\n",
      "\t\tMap output records=49\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1895268352\n",
      "\t\tReduce input groups=49\n",
      "\t\tReduce input records=49\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=1076\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=98\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7708729344\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004317.534010/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004317.534010...\n",
      "Removing temp directory /tmp/buildStripes.nhaas.20170620.004317.534010...\n",
      "WARNING:root:Elapsed time: 53.6111400127 seconds\n",
      "    In minutes: 0.893519000212 mins\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 1\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs -rm -r systems_test_stripes_1\n",
    "!python buildStripes.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stripes on Mini-Test Data Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 53.6 seconds_\n",
    "\n",
    "* _Run time: 0.89 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 563_\n",
    "\n",
    "* _Bytes Written: 2046_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2440_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t{\"limited\": 55, \"female\": 447, \"general\": 92, \"sea\": 62, \"in\": 1201, \"religious\": 59, \"george\": 92, \"biography\": 92, \"city\": 62, \"for\": 59, \"tales\": 123, \"child's\": 1099, \"forms\": 116, \"wales\": 1099, \"christmas\": 1099, \"government\": 102, \"collection\": 239, \"by\": 62, \"case\": 604, \"circumstantial\": 62, \"fairy\": 123, \"of\": 895, \"study\": 604, \"bill\": 59, \"establishing\": 59, \"narrative\": 62, \"the\": 124}\r\n",
      "\"bill\"\t{\"a\": 59, \"religious\": 59, \"for\": 59, \"establishing\": 59}\r\n",
      "\"biography\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"general\": 92}\r\n",
      "\"by\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"sea\": 62}\r\n",
      "\"case\"\t{\"a\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"study\": 604, \"female\": 447, \"in\": 102}\r\n",
      "\"child's\"\t{\"a\": 1099, \"wales\": 1099, \"christmas\": 1099, \"in\": 1099}\r\n",
      "\"christmas\"\t{\"a\": 1099, \"wales\": 1099, \"in\": 1099, \"child's\": 1099}\r\n",
      "\"circumstantial\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"narrative\": 62}\r\n",
      "\"city\"\t{\"a\": 62, \"the\": 62, \"by\": 62, \"sea\": 62}\r\n",
      "\"collection\"\t{\"a\": 239, \"forms\": 116, \"fairy\": 123, \"tales\": 123, \"of\": 239}\r\n",
      "\"establishing\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"for\": 59}\r\n",
      "\"fairy\"\t{\"a\": 123, \"of\": 123, \"tales\": 123, \"collection\": 123}\r\n",
      "\"female\"\t{\"a\": 447, \"case\": 447, \"study\": 447, \"of\": 447}\r\n",
      "\"for\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"establishing\": 59}\r\n",
      "\"forms\"\t{\"a\": 116, \"of\": 116, \"collection\": 116}\r\n",
      "\"general\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"biography\": 92}\r\n",
      "\"george\"\t{\"a\": 92, \"of\": 92, \"biography\": 92, \"general\": 92}\r\n",
      "\"government\"\t{\"a\": 102, \"case\": 102, \"study\": 102, \"in\": 102}\r\n",
      "\"in\"\t{\"a\": 1201, \"case\": 102, \"government\": 102, \"study\": 102, \"child's\": 1099, \"wales\": 1099, \"christmas\": 1099}\r\n",
      "\"limited\"\t{\"a\": 55, \"case\": 55, \"study\": 55, \"of\": 55}\r\n",
      "\"narrative\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"circumstantial\": 62}\r\n",
      "\"of\"\t{\"a\": 895, \"case\": 502, \"circumstantial\": 62, \"george\": 92, \"limited\": 55, \"tales\": 123, \"collection\": 239, \"the\": 62, \"forms\": 116, \"female\": 447, \"narrative\": 62, \"fairy\": 123, \"general\": 92, \"study\": 502, \"biography\": 92}\r\n",
      "\"religious\"\t{\"a\": 59, \"bill\": 59, \"for\": 59, \"establishing\": 59}\r\n",
      "\"sea\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"by\": 62}\r\n",
      "\"study\"\t{\"a\": 604, \"case\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"female\": 447, \"in\": 102}\r\n",
      "\"tales\"\t{\"a\": 123, \"of\": 123, \"fairy\": 123, \"collection\": 123}\r\n",
      "\"the\"\t{\"a\": 124, \"city\": 62, \"circumstantial\": 62, \"of\": 62, \"sea\": 62, \"narrative\": 62, \"by\": 62}\r\n",
      "\"wales\"\t{\"a\": 1099, \"in\": 1099, \"christmas\": 1099, \"child's\": 1099}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_2': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.nhaas.20170620.004413.890907\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004413.890907/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7494154217889837410.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0123\n",
      "  Submitted application application_1497906899862_0123\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0123/\n",
      "  Running job: job_1497906899862_0123\n",
      "  Job job_1497906899862_0123 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0123 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004413.890907/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=101\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=163\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=138\n",
      "\t\tFILE: Number of bytes written=398029\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=471\n",
      "\t\tHDFS: Number of bytes written=163\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=79497216\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=78348800\n",
      "\t\tTotal time spent by all map tasks (ms)=51756\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=155268\n",
      "\t\tTotal time spent by all reduce tasks (ms)=30605\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=153025\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=51756\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=30605\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3390\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=189\n",
      "\t\tInput split bytes=370\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=217\n",
      "\t\tMap output materialized bytes=173\n",
      "\t\tMap output records=7\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1931046912\n",
      "\t\tReduce input groups=7\n",
      "\t\tReduce input records=7\n",
      "\t\tReduce output records=4\n",
      "\t\tReduce shuffle bytes=173\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=14\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7759872000\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004413.890907/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/buildStripes.nhaas.20170620.004413.890907...\n",
      "Removing temp directory /tmp/buildStripes.nhaas.20170620.004413.890907...\n",
      "WARNING:root:Elapsed time: 132.289860964 seconds\n",
      "    In minutes: 2.20483101606 mins\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 2\n",
    "###########################################################################\n",
    "\n",
    "!hdfs dfs -rm -r systems_test_stripes_2\n",
    "!python buildStripes.py -r hadoop atlas-boon-systems-test.txt > systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stripes on System Test 2 Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 132.3 seconds_\n",
    "\n",
    "* _Run time: 2.2 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 138_\n",
    "\n",
    "* _Bytes Written: 98029_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 3390_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"atlas\"\t{\"dipped\": 15, \"boon\": 50}\r\n",
      "\"boon\"\t{\"atlas\": 50, \"dipped\": 10, \"cava\": 10}\r\n",
      "\"cava\"\t{\"dipped\": 10, \"boon\": 10}\r\n",
      "\"dipped\"\t{\"atlas\": 15, \"boon\": 10, \"cava\": 10}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"DocA\"\t{\"X\":20, \"Y\":30, \"Z\":5}\r\n",
      "\"DocB\"\t{\"X\":100, \"Y\":20}\r\n",
      "\"DocC\"\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\r\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Stripes for systems test 3 (given, no need to build stripes)\n",
    "########################################################################\n",
    "\n",
    "with open(\"systems_test_stripes_3\", \"w\") as f:\n",
    "    f.writelines([\n",
    "        '\"DocA\"\\t{\"X\":20, \"Y\":30, \"Z\":5}\\n',\n",
    "        '\"DocB\"\\t{\"X\":100, \"Y\":20}\\n',  \n",
    "        '\"DocC\"\\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\\n'\n",
    "    ])\n",
    "!cat systems_test_stripes_3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted indices for mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.nhaas.20170620.004627.008403\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004627.008403/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7687580488355699665.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0127\n",
      "  Submitted application application_1497906899862_0127\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0127/\n",
      "  Running job: job_1497906899862_0127\n",
      "  Job job_1497906899862_0127 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0127 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004627.008403/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3609\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2192\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1402\n",
      "\t\tFILE: Number of bytes written=399324\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3971\n",
      "\t\tHDFS: Number of bytes written=2192\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12934656\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=10329600\n",
      "\t\tTotal time spent by all map tasks (ms)=8421\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=25263\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4035\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=20175\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8421\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4035\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2680\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=108\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=3308\n",
      "\t\tMap output materialized bytes=1623\n",
      "\t\tMap output records=158\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1894166528\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=158\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=1623\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=316\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7708434432\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004627.008403/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004627.008403...\n",
      "Removing temp directory /tmp/invertedIndex.nhaas.20170620.004627.008403...\n",
      "WARNING:root:Elapsed time: 54.217550993 seconds\n",
      "    In minutes: 0.903625849883 mins\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r hadoop systems_test_stripes_1 > systems_test_index_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inverted Indicies on Mini-Test Data Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 54.2 seconds_\n",
    "\n",
    "* _Run time: 0.9 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 3609_\n",
    "\n",
    "* _Bytes Written: 2192_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2680_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.nhaas.20170620.004721.521416\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004721.521416/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5550599406287433497.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0129\n",
      "  Submitted application application_1497906899862_0129\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0129/\n",
      "  Running job: job_1497906899862_0129\n",
      "  Job job_1497906899862_0129 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0129 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004721.521416/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=245\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=153\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=144\n",
      "\t\tFILE: Number of bytes written=396633\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=607\n",
      "\t\tHDFS: Number of bytes written=153\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=34200576\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14840320\n",
      "\t\tTotal time spent by all map tasks (ms)=22266\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=66798\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5797\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=28985\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=22266\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5797\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3090\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=244\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=206\n",
      "\t\tMap output materialized bytes=190\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1900281856\n",
      "\t\tReduce input groups=4\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=4\n",
      "\t\tReduce shuffle bytes=190\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7767040000\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004721.521416/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004721.521416...\n",
      "Removing temp directory /tmp/invertedIndex.nhaas.20170620.004721.521416...\n",
      "WARNING:root:Elapsed time: 62.4420478344 seconds\n",
      "    In minutes: 1.04070079724 mins\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r hadoop systems_test_stripes_2 > systems_test_index_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inverted Indicies on System Test 2 Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 62.4 seconds_\n",
    "\n",
    "* _Run time: 1.04 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 245_\n",
    "\n",
    "* _Bytes Written: 153_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 3090_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.nhaas.20170620.004824.273211\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004824.273211/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob8157236064607760792.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0131\n",
      "  Submitted application application_1497906899862_0131\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0131/\n",
      "  Running job: job_1497906899862_0131\n",
      "  Job job_1497906899862_0131 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0131 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004824.273211/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=140\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=124\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=98\n",
      "\t\tFILE: Number of bytes written=396527\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=502\n",
      "\t\tHDFS: Number of bytes written=124\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10936320\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=16627200\n",
      "\t\tTotal time spent by all map tasks (ms)=7120\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21360\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6495\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=32475\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7120\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6495\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2770\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=96\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=144\n",
      "\t\tMap output materialized bytes=130\n",
      "\t\tMap output records=9\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1909186560\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce input records=9\n",
      "\t\tReduce output records=5\n",
      "\t\tReduce shuffle bytes=130\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=18\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7774732288\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004824.273211/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/invertedIndex.nhaas.20170620.004824.273211...\n",
      "Removing temp directory /tmp/invertedIndex.nhaas.20170620.004824.273211...\n",
      "WARNING:root:Elapsed time: 56.7551140785 seconds\n",
      "    In minutes: 0.945918567975 mins\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r hadoop systems_test_stripes_3 > systems_test_index_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inverted Indicies on System Test 3 Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 56.76 seconds_\n",
    "\n",
    "* _Run time: 0.95 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 140_\n",
    "\n",
    "* _Bytes Written: 124_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2770_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Systems test  1  - Inverted Index\n",
      "\n",
      "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
      "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
      "     \"biography\" |            a 27 |       general 4 |        george 4\n",
      "            \"by\" |            a 27 |          city 4 |           sea 4\n",
      "          \"case\" |            a 27 |        female 4 |    government 4\n",
      "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
      "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
      "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
      "          \"city\" |            a 27 |            by 4 |           sea 4\n",
      "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
      "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
      "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
      "        \"female\" |            a 27 |          case 7 |           of 15\n",
      "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
      "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
      "       \"general\" |            a 27 |     biography 4 |        george 4\n",
      "        \"george\" |            a 27 |     biography 4 |       general 4\n",
      "    \"government\" |            a 27 |          case 7 |            in 7\n",
      "            \"in\" |            a 27 |          case 7 |       child's 4\n",
      "       \"limited\" |            a 27 |          case 7 |           of 15\n",
      "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
      "            \"of\" |            a 27 |     biography 4 |          case 7\n",
      "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
      "           \"sea\" |            a 27 |            by 4 |          city 4\n",
      "         \"study\" |            a 27 |          case 7 |        female 4\n",
      "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
      "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
      "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
      "\n",
      "Systems test  2  - Inverted Index\n",
      "\n",
      "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
      "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
      "          \"cava\" |          boon 3 |        dipped 3 |                \n",
      "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
      "\n",
      "Systems test  3  - Inverted Index\n",
      "\n",
      "             \"M\" |          DocC 4 |                 |                \n",
      "             \"N\" |          DocC 4 |                 |                \n",
      "             \"X\" |          DocA 3 |          DocB 2 |                \n",
      "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n",
      "             \"Z\" |          DocA 3 |          DocC 4 |                \n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Pretty print systems tests for generating Inverted Index\n",
    "##########################################################\n",
    "import json\n",
    "\n",
    "for i in range(1,4):\n",
    "    print \"\"*100\n",
    "    print \"Systems test \",i,\" - Inverted Index\"\n",
    "    print \"\"*100  \n",
    "    with open(\"systems_test_index_\"+str(i),\"r\") as f:\n",
    "        lines = sorted(f.readlines())\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            word, doc_list = line.split(\"\\t\")\n",
    "            doc_dict = json.loads(doc_list)\n",
    "            stripe=[]\n",
    "            for doc in doc_dict:\n",
    "                stripe.append([doc, doc_dict[doc]])\n",
    "            stripe=sorted(stripe)\n",
    "            stripe.extend([[\"\",\"\"] for _ in xrange(3 - len(stripe))])\n",
    "\n",
    "            print \"{0:>16} |{1:>16} |{2:>16} |{3:>16}\".format(\n",
    "              (word), stripe[0][0]+\" \"+str(stripe[0][1]), stripe[1][0]+\" \"+str(stripe[1][1]), stripe[2][0]+\" \"+str(stripe[2][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities for mini-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.nhaas.20170620.004921.305567\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.004921.305567/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob8278515987537768873.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0134\n",
      "  Submitted application application_1497906899862_0134\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0134/\n",
      "  Running job: job_1497906899862_0134\n",
      "  Job job_1497906899862_0134 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0134 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.004921.305567/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3288\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=35050\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3756\n",
      "\t\tFILE: Number of bytes written=406303\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3638\n",
      "\t\tHDFS: Number of bytes written=35050\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18173952\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9031680\n",
      "\t\tTotal time spent by all map tasks (ms)=11832\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=35496\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3528\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17640\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11832\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3528\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2590\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=182\n",
      "\t\tInput split bytes=350\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=19239\n",
      "\t\tMap output materialized bytes=4940\n",
      "\t\tMap output records=673\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1901486080\n",
      "\t\tReduce input groups=378\n",
      "\t\tReduce input records=673\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=4940\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1346\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7729766400\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.004921.305567/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.004921.305567...\n",
      "Removing temp directory /tmp/similarity.nhaas.20170620.004921.305567...\n",
      "WARNING:root:Elapsed time: 57.3197870255 seconds\n",
      "    In minutes: 0.955329783758 mins\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_1 > systems_test_similarities_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Similarities on Mini Test Data Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 57.32 seconds_\n",
    "\n",
    "* _Run time: 0.95 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 3288_\n",
    "\n",
    "* _Bytes Written: 35050_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2590_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.nhaas.20170620.005018.874000\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005018.874000/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob596330617695031529.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0136\n",
      "  Submitted application application_1497906899862_0136\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0136/\n",
      "  Running job: job_1497906899862_0136\n",
      "  Job job_1497906899862_0136 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0136 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005018.874000/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=230\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=511\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=130\n",
      "\t\tFILE: Number of bytes written=397925\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=580\n",
      "\t\tHDFS: Number of bytes written=511\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17679360\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17825280\n",
      "\t\tTotal time spent by all map tasks (ms)=11510\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=34530\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6963\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=34815\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11510\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6963\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2740\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=71\n",
      "\t\tInput split bytes=350\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=212\n",
      "\t\tMap output materialized bytes=191\n",
      "\t\tMap output records=8\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1899790336\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=191\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=16\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7748861952\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005018.874000/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005018.874000...\n",
      "Removing temp directory /tmp/similarity.nhaas.20170620.005018.874000...\n",
      "WARNING:root:Elapsed time: 57.9054648876 seconds\n",
      "    In minutes: 0.96509108146 mins\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_2 > systems_test_similarities_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities on Systems Test 2 Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 57.91 seconds_\n",
    "\n",
    "* _Run time: 0.97 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 230_\n",
    "\n",
    "* _Bytes Written: 51_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2740_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.nhaas.20170620.005117.015081\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005117.015081/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3724905999905458272.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0138\n",
      "  Submitted application application_1497906899862_0138\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0138/\n",
      "  Running job: job_1497906899862_0138\n",
      "  Job job_1497906899862_0138 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0138 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005117.015081/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=186\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=327\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=80\n",
      "\t\tFILE: Number of bytes written=397798\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=536\n",
      "\t\tHDFS: Number of bytes written=327\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=24182784\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11059200\n",
      "\t\tTotal time spent by all map tasks (ms)=15744\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=47232\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4320\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=21600\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=15744\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4320\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3420\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=171\n",
      "\t\tInput split bytes=350\n",
      "\t\tMap input records=5\n",
      "\t\tMap output bytes=125\n",
      "\t\tMap output materialized bytes=111\n",
      "\t\tMap output records=5\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1895182336\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=111\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=10\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7732977664\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005117.015081/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/similarity.nhaas.20170620.005117.015081...\n",
      "Removing temp directory /tmp/similarity.nhaas.20170620.005117.015081...\n",
      "WARNING:root:Elapsed time: 59.1342320442 seconds\n",
      "    In minutes: 0.98557053407 mins\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_3 > systems_test_similarities_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Similarities on Systems Test 3 Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 59.13 seconds_\n",
    "\n",
    "* _Run time: 0.99 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 186_\n",
    "\n",
    "* _Bytes Written: 327_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 3420_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Systems test  1  - Similarity measures\n",
      "\n",
      "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.334842 |       a - bill |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |  a - biography |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |         a - by |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |       a - case |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |    a - child's |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |  a - christmas |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |a - circumstantial |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |       a - city |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.384281 | a - collection |       0.344265 |       0.142857 |       0.800000 |       0.250000\n",
      "       0.334842 |a - establishing |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |      a - fairy |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |     a - female |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |        a - for |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.273413 |      a - forms |       0.222222 |       0.071429 |       0.666667 |       0.133333\n",
      "       0.334842 |    a - general |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |     a - george |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 | a - government |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |         a - in |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |    a - limited |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |  a - narrative |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.698916 |         a - of |       0.695666 |       0.500000 |       0.933333 |       0.666667\n",
      "       0.334842 |  a - religious |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.334842 |        a - sea |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |      a - study |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |      a - tales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.465201 |        a - the |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "       0.334842 |      a - wales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "       0.223214 |bill - biography |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |      bill - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    bill - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 | bill - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    bill - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |bill - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.712500 |bill - establishing |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |   bill - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  bill - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |     bill - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.268597 |   bill - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 | bill - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  bill - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      bill - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 | bill - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |bill - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |      bill - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.712500 |bill - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |     bill - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |   bill - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   bill - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |     bill - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   bill - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | biography - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |biography - case |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |biography - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |biography - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |biography - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |biography - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.419343 |biography - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.223214 |biography - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |biography - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |biography - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |biography - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 |biography - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.712500 |biography - general |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.712500 |biography - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |biography - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 | biography - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |biography - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |biography - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 | biography - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |biography - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |biography - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |biography - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |biography - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |biography - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |biography - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      by - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   by - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | by - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |by - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.712500 |      by - city |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.205207 |by - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |by - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     by - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    by - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |       by - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |     by - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |   by - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    by - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |by - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |        by - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   by - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 | by - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.271593 |        by - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.223214 | by - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |       by - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.180200 |     by - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |     by - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |       by - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |     by - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 | case - child's |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |case - christmas |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |case - circumstantial |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.180200 |    case - city |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.317849 |case - collection |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.180200 |case - establishing |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.365956 |   case - fairy |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.559350 |  case - female |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.180200 |     case - for |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.438276 |   case - forms |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.365956 | case - general |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |  case - george |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.559350 |case - government |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.389610 |      case - in |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.559350 | case - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.365956 |case - narrative |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.386912 |      case - of |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.180200 |case - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |     case - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.830357 |   case - study |       0.857143 |       0.750000 |       0.857143 |       0.857143\n",
      "       0.365956 |   case - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.255952 |     case - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.365956 |   case - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.712500 |child's - christmas |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |child's - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 | child's - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |child's - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |child's - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  child's - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |child's - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |child's - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |child's - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |   child's - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |child's - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |child's - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |   child's - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.223214 |child's - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  child's - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |child's - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |child's - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |  child's - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.712500 |child's - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |christmas - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |christmas - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |christmas - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |christmas - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |christmas - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |christmas - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 | christmas - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |christmas - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 | christmas - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.223214 |christmas - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |christmas - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |christmas - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |christmas - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |christmas - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.712500 |christmas - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.458333 |circumstantial - city |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.419343 |circumstantial - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.223214 |circumstantial - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |circumstantial - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |circumstantial - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |circumstantial - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 |circumstantial - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.458333 |circumstantial - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |circumstantial - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |circumstantial - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |circumstantial - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |circumstantial - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.712500 |circumstantial - narrative |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.410147 |circumstantial - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |circumstantial - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |circumstantial - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |circumstantial - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |circumstantial - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |circumstantial - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |circumstantial - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |city - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |city - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   city - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  city - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |     city - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |   city - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 | city - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  city - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |city - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      city - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 | city - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |city - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.271593 |      city - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.223214 |city - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |     city - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.180200 |   city - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |   city - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |     city - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |   city - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.205207 |collection - establishing |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.646872 |collection - fairy |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.419343 |collection - female |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.205207 |collection - for |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.504099 |collection - forms |       0.516398 |       0.333333 |       0.666667 |       0.500000\n",
      "       0.419343 |collection - general |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |collection - george |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.205207 |collection - government |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.156652 |collection - in |       0.169031 |       0.090909 |       0.200000 |       0.166667\n",
      "       0.419343 |collection - limited |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.419343 |collection - narrative |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "       0.477970 |collection - of |       0.461880 |       0.250000 |       0.800000 |       0.400000\n",
      "       0.205207 |collection - religious |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.205207 |collection - sea |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.317849 |collection - study |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.646872 |collection - tales |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "       0.317849 |collection - the |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "       0.205207 |collection - wales |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "       0.223214 |establishing - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.712500 |establishing - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.268597 |establishing - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |establishing - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |establishing - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |establishing - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |establishing - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |establishing - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.712500 |establishing - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |establishing - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |establishing - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |establishing - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |establishing - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |establishing - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 | fairy - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |    fairy - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.868292 |  fairy - forms |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.458333 |fairy - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 | fairy - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.223214 |fairy - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |     fairy - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |fairy - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |fairy - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |     fairy - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |fairy - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |    fairy - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |  fairy - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.712500 |  fairy - tales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.365956 |    fairy - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |  fairy - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   female - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 | female - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.458333 |female - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |female - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.712500 |female - government |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.559350 |    female - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       1.000000 |female - limited |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.458333 |female - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |    female - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |female - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   female - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 | female - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.458333 | female - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |   female - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 | female - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.268597 |    for - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.223214 |  for - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   for - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |for - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |       for - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |  for - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |for - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 |       for - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.712500 |for - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |      for - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    for - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |    for - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |      for - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |    for - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.553861 |forms - general |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.553861 | forms - george |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.268597 |forms - government |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.215666 |     forms - in |       0.218218 |       0.111111 |       0.333333 |       0.200000\n",
      "       0.553861 |forms - limited |       0.577350 |       0.400000 |       0.666667 |       0.571429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.553861 |forms - narrative |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.328008 |     forms - of |       0.298142 |       0.125000 |       0.666667 |       0.222222\n",
      "       0.268597 |forms - religious |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.268597 |    forms - sea |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.438276 |  forms - study |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.868292 |  forms - tales |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "       0.438276 |    forms - the |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "       0.268597 |  forms - wales |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "       0.712500 |general - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |general - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |   general - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |general - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |general - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |   general - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |general - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  general - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |general - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |general - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |  general - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |general - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |george - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    george - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |george - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.458333 |george - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |    george - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |george - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |   george - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 | george - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 | george - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |   george - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 | george - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |government - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.712500 |government - limited |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "       0.223214 |government - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.410147 |government - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |government - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |government - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |government - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |government - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |government - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.458333 |government - wales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |   in - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.180200 | in - narrative |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.287991 |        in - of |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.180200 | in - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.180200 |       in - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.389610 |     in - study |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "       0.180200 |     in - tales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.126374 |       in - the |       0.142857 |       0.076923 |       0.142857 |       0.142857\n",
      "       0.559350 |     in - wales |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.458333 |limited - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.410147 |   limited - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |limited - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.223214 |  limited - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |limited - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.458333 |limited - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |  limited - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |limited - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.410147 | narrative - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.223214 |narrative - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.458333 |narrative - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.365956 |narrative - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.458333 |narrative - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "       0.559350 |narrative - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |narrative - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.134980 | of - religious |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.271593 |       of - sea |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "       0.386912 |     of - study |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "       0.410147 |     of - tales |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "       0.287991 |       of - the |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "       0.134980 |     of - wales |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "       0.223214 |religious - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |religious - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |religious - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |religious - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |religious - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    sea - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "       0.223214 |    sea - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.559350 |      sea - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "       0.223214 |    sea - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.365956 |  study - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.255952 |    study - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "       0.365956 |  study - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.365956 |    tales - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "       0.223214 |  tales - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "       0.180200 |    the - wales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "\n",
      "Systems test  2  - Similarity measures\n",
      "\n",
      "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.389562 |   atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       1.000000 |   atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "       0.389562 | atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.389562 |    boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "       0.625000 |  boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
      "       0.389562 |  cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "\n",
      "Systems test  3  - Similarity measures\n",
      "\n",
      "        average |           pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "       0.820791 |    DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
      "       0.553861 |    DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "       0.346722 |    DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Pretty print systems tests\n",
    "############################################\n",
    "\n",
    "import json\n",
    "for i in range(1,4):\n",
    "  print ''*110\n",
    "  print \"Systems test \",i,\" - Similarity measures\"\n",
    "  print ''*110\n",
    "  print \"{0:>15} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "          \"average\", \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\")\n",
    "  print '-'*110\n",
    "\n",
    "  with open(\"systems_test_similarities_\"+str(i),\"r\") as f:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "          line = line.strip()\n",
    "          avg,stripe = line.split(\"\\t\")\n",
    "          stripe = json.loads(stripe)\n",
    "\n",
    "          print \"{0:>15f} |{1:>15} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "              float(avg), stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.1 <a name=\"5.4.1\"></a>Full-scale experiment: EDA of Google n-grams dataset (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Do some EDA on this dataset using mrjob, e.g., \n",
    "\n",
    "- A. Longest 5-gram (number of characters)\n",
    "- B. Top 10 most frequent words (please use the count information), i.e., unigrams\n",
    "- C. 20 Most/Least densely appearing words (count/pages_count) sorted in decreasing order of relative frequency \n",
    "- D. Distribution of 5-gram sizes (character length).  E.g., count (using the count field) up how many times a 5-gram of 50 characters shows up. Plot the data graphically using a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - A. Longest 5-gram (number of characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing longest5gram.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile longest5gram.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import logging\n",
    "import time\n",
    "\n",
    "class longest5gram(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.A\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(longest5gram, self).__init__(args)\n",
    "        self.max_count = 0\n",
    "        self.max_grams = []\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        \n",
    "        char_count = 0\n",
    "        \n",
    "        # Count characters\n",
    "        for word in words:\n",
    "            char_count += len(word)\n",
    "        \n",
    "        # Optimization: we track the max count local to the current mapper instance. If records\n",
    "        # have higher count than the max, we output them and update the max. We don't yield\n",
    "        # records that are smaller than the local max. \n",
    "        # Even some non-max records are passed on, the good thing about this is that it is extremely memory efficient\n",
    "        # in that it uses constant memory.\n",
    "        if char_count > self.max_count:\n",
    "            self.max_count = char_count\n",
    "            yield (words), char_count\n",
    "        elif char_count == self.max_count:\n",
    "            yield (words), char_count\n",
    "            \n",
    "    \n",
    "    def combiner(self, ngram, char_counts):\n",
    "        current_max = max(char_counts)\n",
    "        \n",
    "        # Optimization: we track the max count local to the current combiner instance. If records\n",
    "        # have higher count than the max, we output them and update the max. We don't yield\n",
    "        # records that are smaller than the local max, drastically reducing work on shuffling and sorting\n",
    "        # Even some non-max or local max records are passed on, the good thing about this is that it is extremely \n",
    "        # memory efficient in that it uses constant memory (just 1 integer :)\n",
    "        if current_max > self.max_count:\n",
    "            self.max_count = current_max\n",
    "            yield ngram, current_max\n",
    "        elif current_max == self.max_count:\n",
    "            yield ngram, current_max\n",
    "    \n",
    "    def reducer(self, ngram, char_counts):\n",
    "            \n",
    "        current_count = max(char_counts)\n",
    "\n",
    "        # Track in max_grams the n-grams with the max count of words\n",
    "        if current_count > self.max_count:\n",
    "            self.max_count = current_count\n",
    "            self.max_grams = [(current_count, ngram)]\n",
    "        elif current_count == self.max_count:\n",
    "            self.max_grams.append((current_count, ngram))\n",
    "\n",
    "    def reducer_final(self):\n",
    "        # Once\n",
    "        for gram in self.max_grams:\n",
    "            yield gram[0], gram[1]\n",
    "\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        # We need 1 reducer for this approach. However the optimizations in the mappers and combiners\n",
    "        # help us ensure that a small percentage of records get to the reducer\n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'1',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k2,2nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner,\n",
    "                    reducer_final = self.reducer_final\n",
    "                      )\n",
    "                 ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.A\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    longest5gram.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_5.4.1.a_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/longest5gram.nhaas.20170620.005218.886918\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.005218.886918/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2372923994912197776.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0141\n",
      "  Submitted application application_1497906899862_0141\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0141/\n",
      "  Running job: job_1497906899862_0141\n",
      "  Job job_1497906899862_0141 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0141 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.005218.886918/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=106\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=160\n",
      "\t\tFILE: Number of bytes written=400382\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1007\n",
      "\t\tHDFS: Number of bytes written=106\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=53383680\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=32184320\n",
      "\t\tTotal time spent by all map tasks (ms)=34755\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=104265\n",
      "\t\tTotal time spent by all reduce tasks (ms)=12572\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=62860\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=34755\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=12572\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3530\n",
      "\t\tCombine input records=3\n",
      "\t\tCombine output records=3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=118\n",
      "\t\tInput split bytes=444\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=154\n",
      "\t\tMap output materialized bytes=176\n",
      "\t\tMap output records=3\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1914478592\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=2\n",
      "\t\tReduce shuffle bytes=176\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=6\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7734489088\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.005218.886918/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.005218.886918...\n",
      "Removing temp directory /tmp/longest5gram.nhaas.20170620.005218.886918...\n",
      "WARNING:root:Elapsed time: 518.493923903 seconds\n",
      "    In minutes: 8.64156539838 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r systems_test_stripes_5.4.1.a_1\n",
    "!python longest5gram.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > systems_test_stripes_5.4.1.a_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Longest 5 Gram on Mini Test Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 518.49 seconds_\n",
    "\n",
    "* _Run time: 8.64 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 563_\n",
    "\n",
    "* _Bytes Written: 106_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 3530_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat systems_test_stripes_5.4.1.a_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_stripes_5.4.1.a': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/longest5gram.nhaas.20170620.010100.105837\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.010100.105837/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7432488386907926489.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1497906899862_0143\n",
      "  Submitted application application_1497906899862_0143\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0143/\n",
      "  Running job: job_1497906899862_0143\n",
      "  Job job_1497906899862_0143 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0143 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.010100.105837/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=360\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=37748\n",
      "\t\tFILE: Number of bytes written=25555787\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=360\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=2\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=6807410688\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11023360\n",
      "\t\tTotal time spent by all map tasks (ms)=4431908\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=13295724\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4306\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=21530\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=4431908\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4306\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=530340\n",
      "\t\tCombine input records=2699\n",
      "\t\tCombine output records=1108\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=28371\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=172790\n",
      "\t\tMap output materialized bytes=63827\n",
      "\t\tMap output records=2699\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=153973510144\n",
      "\t\tReduce input groups=1108\n",
      "\t\tReduce input records=1108\n",
      "\t\tReduce output records=2\n",
      "\t\tReduce shuffle bytes=63827\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=2216\n",
      "\t\tTotal committed heap usage (bytes)=299992875008\n",
      "\t\tVirtual memory (bytes) snapshot=421257048064\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.010100.105837/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/longest5gram.nhaas.20170620.010100.105837...\n",
      "Removing temp directory /tmp/longest5gram.nhaas.20170620.010100.105837...\n",
      "WARNING:root:Elapsed time: 152.978531122 seconds\n",
      "    In minutes: 2.54964218537 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_stripes_5.4.1.a\n",
    "!python longest5gram.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > full_stripes_5.4.1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Longest 5 Gram on Full Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 152.98 seconds_\n",
    "\n",
    "* _Run time: 2.55 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 2156069116_\n",
    "\n",
    "* _Bytes Written: 360_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 191_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 530340_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat full_stripes_5.4.1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Stats: \n",
    "## example: \n",
    "## Longest 5grams MR stats\n",
    "\n",
    "    ec2_instance_type: m3.xlarge\n",
    "    num_ec2_instances: 15\n",
    "\n",
    "__Step 1:__  \n",
    "\n",
    "    RUNNING for 107.0s ~= 2 minutes  \n",
    "    Reduce tasks = 16 \n",
    "    \n",
    "__Step 2:__   \n",
    "\n",
    "    RUNNING for 108.8s ~= 2 minutes\n",
    "    Reduce tasks = 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - B. Top 10 most frequent words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mostFrequentWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostFrequentWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import logging\n",
    "import time\n",
    "\n",
    "class mostFrequentWords(MRJob):\n",
    "\n",
    "    # START STUDENT CODE 5.4.1.B\n",
    "            \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        count = int(splits[1])\n",
    "        \n",
    "        for word in words:\n",
    "            yield word, count\n",
    "            \n",
    "    \n",
    "    def combiner(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield word, total\n",
    "    \n",
    "    def reducer(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield total, word\n",
    "    \n",
    "    def max_reducer(self, count, words):\n",
    "        for word in words:\n",
    "            yield word, count\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.B\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    mostFrequentWords.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_5.4.1.b_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/mostFrequentWords.nhaas.20170620.010335.811516\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010335.811516/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob6581458571265853595.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0144\n",
      "  Submitted application application_1497906899862_0144\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0144/\n",
      "  Running job: job_1497906899862_0144\n",
      "  Job job_1497906899862_0144 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0144 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010335.811516/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=357\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=430\n",
      "\t\tFILE: Number of bytes written=400124\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1017\n",
      "\t\tHDFS: Number of bytes written=357\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=27199488\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14912000\n",
      "\t\tTotal time spent by all map tasks (ms)=17708\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=53124\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5825\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29125\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=17708\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5825\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2970\n",
      "\t\tCombine input records=50\n",
      "\t\tCombine output records=31\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=104\n",
      "\t\tInput split bytes=454\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=602\n",
      "\t\tMap output materialized bytes=458\n",
      "\t\tMap output records=50\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1890709504\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=31\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=458\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=62\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7720751104\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4987583826410924967.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0145\n",
      "  Submitted application application_1497906899862_0145\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0145/\n",
      "  Running job: job_1497906899862_0145\n",
      "  Job job_1497906899862_0145 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0145 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010335.811516/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=536\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=357\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=396\n",
      "\t\tFILE: Number of bytes written=399589\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=904\n",
      "\t\tHDFS: Number of bytes written=357\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10272768\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14871040\n",
      "\t\tTotal time spent by all map tasks (ms)=6688\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20064\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5809\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29045\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6688\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5809\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2400\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=87\n",
      "\t\tInput split bytes=368\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=385\n",
      "\t\tMap output materialized bytes=437\n",
      "\t\tMap output records=28\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1899945984\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=28\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=437\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=56\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7736762368\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010335.811516/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010335.811516...\n",
      "Removing temp directory /tmp/mostFrequentWords.nhaas.20170620.010335.811516...\n",
      "WARNING:root:Elapsed time: 92.9325778484 seconds\n",
      "    In minutes: 1.54887629747 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r systems_test_stripes_5.4.1.b_1\n",
    "!python mostFrequentWords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > systems_test_stripes_5.4.1.b_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Most Frequent Words on Test Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 92.93 seconds_\n",
    "\n",
    "* _Run time: 1.55 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 536_\n",
    "\n",
    "* _Bytes Written: 357_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2400_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t2217\r\n",
      "\"in\"\t1201\r\n",
      "\"wales\"\t1099\r\n",
      "\"christmas\"\t1099\r\n",
      "\"child's\"\t1099\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 systems_test_stripes_5.4.1.b_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_mostFrequentWords_5.4.1.b': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/mostFrequentWords.nhaas.20170620.010511.474235\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010511.474235/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob6614654530498245934.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1497906899862_0146\n",
      "  Submitted application application_1497906899862_0146\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0146/\n",
      "  Running job: job_1497906899862_0146\n",
      "  Job job_1497906899862_0146 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0146 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010511.474235/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4158739\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=39015541\n",
      "\t\tFILE: Number of bytes written=138217972\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=4158739\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=44009364480\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=311751680\n",
      "\t\tTotal time spent by all map tasks (ms)=28651930\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=85955790\n",
      "\t\tTotal time spent by all reduce tasks (ms)=121778\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=608890\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=28651930\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=121778\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=15406280\n",
      "\t\tCombine input records=293411330\n",
      "\t\tCombine output records=6822745\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=121283\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=3430141090\n",
      "\t\tMap output materialized bytes=73800744\n",
      "\t\tMap output records=293411330\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154684850176\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=6822745\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=73800744\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13645490\n",
      "\t\tTotal committed heap usage (bytes)=298060349440\n",
      "\t\tVirtual memory (bytes) snapshot=421250695168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3451930388618934169.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0149\n",
      "  Submitted application application_1497906899862_0149\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0149/\n",
      "  Running job: job_1497906899862_0149\n",
      "  Job job_1497906899862_0149 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0149 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010511.474235/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4176522\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4158739\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2953963\n",
      "\t\tFILE: Number of bytes written=6321979\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4176890\n",
      "\t\tHDFS: Number of bytes written=4158739\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=20491776\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=38074880\n",
      "\t\tTotal time spent by all map tasks (ms)=13341\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=40023\n",
      "\t\tTotal time spent by all reduce tasks (ms)=14873\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=74365\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13341\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=14873\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=13650\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=191\n",
      "\t\tInput split bytes=368\n",
      "\t\tMap input records=269339\n",
      "\t\tMap output bytes=4428078\n",
      "\t\tMap output materialized bytes=2969260\n",
      "\t\tMap output records=269339\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1954492416\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=269339\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=2969260\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538678\n",
      "\t\tTotal committed heap usage (bytes)=5280104448\n",
      "\t\tVirtual memory (bytes) snapshot=7764561920\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010511.474235/output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostFrequentWords.nhaas.20170620.010511.474235...\n",
      "Removing temp directory /tmp/mostFrequentWords.nhaas.20170620.010511.474235...\n",
      "WARNING:root:Elapsed time: 479.481426001 seconds\n",
      "    In minutes: 7.99135710001 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_mostFrequentWords_5.4.1.b\n",
    "!python mostFrequentWords.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > full_mostFrequentWords_5.4.1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Most Frequent Words on Full Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 479.48 seconds_\n",
    "\n",
    "* _Run time: 7.99 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 4176522_\n",
    "\n",
    "* _Bytes Written: 4158739_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 13650_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\"\t5490815394\r\n",
      "\"of\"\t3698583299\r\n",
      "\"to\"\t2227866570\r\n",
      "\"in\"\t1421312776\r\n",
      "\"a\"\t1361123022\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 full_mostFrequentWords_5.4.1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words MR stats\n",
    "    \n",
    "    ec2_instance_type: m3.xlarge\n",
    "    num_ec2_instances: 15\n",
    "    \n",
    "__Step 1:__   \n",
    "\n",
    "    RUNNING for 590.7s ~= 10 minutes   \n",
    "    Launched map tasks=191  \n",
    "    Launched reduce tasks=57   \n",
    "\n",
    "__Step 2:__  \n",
    "\n",
    "    RUNNING for 76.6s   \n",
    "    Launched map tasks=110\n",
    "    Launched reduce tasks=16  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - C. 20 Most/Least densely appearing words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mostLeastDenseWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostLeastDenseWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import re\n",
    "import numpy as np\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class mostLeastDenseWords(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.C\n",
    "           \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def __init__(self, args):\n",
    "        super(mostLeastDenseWords, self).__init__(args)\n",
    "        self.total_word_count = None\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        count = int(splits[1])\n",
    "        \n",
    "        for word in words:\n",
    "            yield \"*\", count\n",
    "            yield word, count\n",
    "            \n",
    "    \n",
    "    def combiner(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield word, total\n",
    "    \n",
    "    def reducer(self, word, counts):\n",
    "    \n",
    "        total = sum(count for count in counts)\n",
    "        \n",
    "        if word == \"*\":\n",
    "            self.total_word_count = total\n",
    "        else:\n",
    "            yield float(total) / float(self.total_word_count), word\n",
    "    \n",
    "    def max_reducer(self, count, words):\n",
    "        for word in words:\n",
    "            yield word, count\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-g -k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "    \n",
    "    # END STUDENT CODE 5.4.1.C\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    mostLeastDenseWords.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `systems_test_stripes_5.4.1.c_1': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/mostLeastDenseWords.nhaas.20170620.011313.660889\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011313.660889/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5742519547021727030.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0152\n",
      "  Submitted application application_1497906899862_0152\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0152/\n",
      "  Running job: job_1497906899862_0152\n",
      "  Job job_1497906899862_0152 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0152 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011313.660889/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=850\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=447\n",
      "\t\tFILE: Number of bytes written=400256\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1021\n",
      "\t\tHDFS: Number of bytes written=850\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18196992\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17111040\n",
      "\t\tTotal time spent by all map tasks (ms)=11847\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=35541\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6684\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=33420\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11847\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6684\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2660\n",
      "\t\tCombine input records=100\n",
      "\t\tCombine output records=33\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=58\n",
      "\t\tInput split bytes=458\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=1032\n",
      "\t\tMap output materialized bytes=477\n",
      "\t\tMap output records=100\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1897111552\n",
      "\t\tReduce input groups=29\n",
      "\t\tReduce input records=33\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=477\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=66\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7751966720\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7037421152185499590.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0153\n",
      "  Submitted application application_1497906899862_0153\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0153/\n",
      "  Running job: job_1497906899862_0153\n",
      "  Job job_1497906899862_0153 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0153 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011313.660889/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1275\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=850\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=633\n",
      "\t\tFILE: Number of bytes written=400262\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1647\n",
      "\t\tHDFS: Number of bytes written=850\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17315328\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15278080\n",
      "\t\tTotal time spent by all map tasks (ms)=11273\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=33819\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5968\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29840\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11273\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5968\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2460\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=88\n",
      "\t\tInput split bytes=372\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=878\n",
      "\t\tMap output materialized bytes=780\n",
      "\t\tMap output records=28\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1907658752\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=28\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=780\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=56\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7742083072\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011313.660889/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011313.660889...\n",
      "Removing temp directory /tmp/mostLeastDenseWords.nhaas.20170620.011313.660889...\n",
      "WARNING:root:Elapsed time: 91.8222980499 seconds\n",
      "    In minutes: 1.53037163417 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r systems_test_stripes_5.4.1.c_1\n",
    "!python mostLeastDenseWords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > systems_test_stripes_5.4.1.c_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Most/Least Dense Words on Test Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 91.82 seconds_\n",
    "\n",
    "* _Run time: 1.53 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 1275_\n",
    "\n",
    "* _Bytes Written: 850_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2660_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t0.20000000000000001\r\n",
      "\"in\"\t0.1083446098331078\r\n",
      "\"wales\"\t0.099142986017140278\r\n",
      "\"christmas\"\t0.099142986017140278\r\n",
      "\"child's\"\t0.099142986017140278\r\n",
      "\"of\"\t0.091204330175913395\r\n",
      "\"study\"\t0.054488046910239063\r\n",
      "\"case\"\t0.054488046910239063\r\n",
      "\"female\"\t0.04032476319350474\r\n",
      "\"collection\"\t0.021560667568786648\r\n",
      "\"the\"\t0.011186287776274244\r\n",
      "\"tales\"\t0.011096075778078484\r\n",
      "\"fairy\"\t0.011096075778078484\r\n",
      "\"forms\"\t0.010464591790708164\r\n",
      "\"government\"\t0.0092016238159675235\r\n",
      "\"george\"\t0.0082995038340099234\r\n",
      "\"general\"\t0.0082995038340099234\r\n",
      "\"biography\"\t0.0082995038340099234\r\n",
      "\"city\"\t0.0055931438881371221\r\n",
      "\"circumstantial\"\t0.0055931438881371221\r\n",
      "\"by\"\t0.0055931438881371221\r\n",
      "\"sea\"\t0.0055931438881371221\r\n",
      "\"narrative\"\t0.0055931438881371221\r\n",
      "\"religious\"\t0.0053225078935498424\r\n",
      "\"establishing\"\t0.0053225078935498424\r\n",
      "\"for\"\t0.0053225078935498424\r\n",
      "\"bill\"\t0.0053225078935498424\r\n",
      "\"limited\"\t0.0049616599007668016\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_5.4.1.c_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_mostLeastDenseWords_5.4.1.c': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/mostLeastDenseWords.nhaas.20170620.011448.287912\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011448.287912/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob8432919336459876530.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1497906899862_0155\n",
      "  Submitted application application_1497906899862_0155\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0155/\n",
      "  Running job: job_1497906899862_0155\n",
      "  Job job_1497906899862_0155 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0155 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011448.287912/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=9190412\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=39018054\n",
      "\t\tFILE: Number of bytes written=138229588\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=9190412\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=77655894528\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=361827840\n",
      "\t\tTotal time spent by all map tasks (ms)=50557223\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=151671669\n",
      "\t\tTotal time spent by all reduce tasks (ms)=141339\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=706695\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=50557223\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=141339\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=29348380\n",
      "\t\tCombine input records=586822660\n",
      "\t\tCombine output records=6822933\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=170502\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=5878243690\n",
      "\t\tMap output materialized bytes=73804117\n",
      "\t\tMap output records=586822660\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154843693056\n",
      "\t\tReduce input groups=269340\n",
      "\t\tReduce input records=6822933\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=73804117\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13645866\n",
      "\t\tTotal committed heap usage (bytes)=295298400256\n",
      "\t\tVirtual memory (bytes) snapshot=421503004672\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4783814955095289495.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0158\n",
      "  Submitted application application_1497906899862_0158\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0158/\n",
      "  Running job: job_1497906899862_0158\n",
      "  Job job_1497906899862_0158 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0158 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011448.287912/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=9313798\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=9190412\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3749377\n",
      "\t\tFILE: Number of bytes written=8032245\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=9314170\n",
      "\t\tHDFS: Number of bytes written=9190412\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=21327360\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=46732800\n",
      "\t\tTotal time spent by all map tasks (ms)=13885\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=41655\n",
      "\t\tTotal time spent by all reduce tasks (ms)=18255\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=91275\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13885\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=18255\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=19600\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=224\n",
      "\t\tInput split bytes=372\n",
      "\t\tMap input records=269339\n",
      "\t\tMap output bytes=9459751\n",
      "\t\tMap output materialized bytes=3884019\n",
      "\t\tMap output records=269339\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1943277568\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=269339\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=3884019\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538678\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7762075648\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011448.287912/output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/mostLeastDenseWords.nhaas.20170620.011448.287912...\n",
      "Removing temp directory /tmp/mostLeastDenseWords.nhaas.20170620.011448.287912...\n",
      "WARNING:root:Elapsed time: 713.757820129 seconds\n",
      "    In minutes: 11.8959636688 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_mostLeastDenseWords_5.4.1.c\n",
    "!python mostLeastDenseWords.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > full_mostLeastDenseWords_5.4.1.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Most/Least Dense Words on Full Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 713.76 seconds_\n",
    "\n",
    "* _Run time: 11.90 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 9313798_\n",
    "\n",
    "* _Bytes Written: 9190412_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 19600_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Highest frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"particulars\"\t9.999991202155478e-06\r\n",
      "\"venn\"\t9.9998902747203268e-08\r\n",
      "\"shortage\"\t9.9992645246223945e-06\r\n",
      "\"melville's\"\t9.9978717260173162e-08\r\n",
      "\"heine\"\t9.9978717260173162e-08\r\n",
      "\"gloat\"\t9.9978717260173162e-08\r\n",
      "\"exxon\"\t9.9978717260173162e-08\r\n",
      "\"anachronistic\"\t9.9978717260173162e-08\r\n",
      "\"trail\"\t9.9970239355620498e-06\r\n",
      "\"letzten\"\t9.9958531773143042e-08\r\n",
      "\"playgrounds\"\t9.9958531773143042e-08\r\n",
      "\"breathings\"\t9.9958531773143042e-08\r\n",
      "\"exceptionable\"\t9.9958531773143042e-08\r\n",
      "\"formalize\"\t9.9958531773143042e-08\r\n",
      "\"hates\"\t9.9942383383518938e-07\r\n",
      "\"coastwise\"\t9.9938346286112922e-08\r\n",
      "\"dividers\"\t9.9938346286112922e-08\r\n",
      "\"assents\"\t9.9938346286112922e-08\r\n",
      "\"residents\"\t9.9936529592280203e-06\r\n",
      "\"smiths\"\t9.9918160799082802e-08\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 full_mostLeastDenseWords_5.4.1.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"continued\"\t0.00010249356653279443\r\n",
      "\"twenty\"\t0.0001022841017338829\r\n",
      "\"heat\"\t0.00010214243998590554\r\n",
      "\"test\"\t0.00010213036906466152\r\n",
      "\"lines\"\t0.00010208735379180034\r\n",
      "\"towards\"\t0.00010163723761651575\r\n",
      "\"difficulty\"\t0.00010160754476509445\r\n",
      "\"income\"\t0.00010148736037531712\r\n",
      "\"mass\"\t0.00010128009579449188\r\n",
      "\"especially\"\t0.00010121792449443911\r\n",
      "\"kingdom\"\t0.00010088728621688579\r\n",
      "\"religion\"\t0.00010079972157414914\r\n",
      "\"former\"\t0.00010066784978738138\r\n",
      "\"obtain\"\t0.00010047905492718869\r\n",
      "\"aspects\"\t0.00010047713730592082\r\n",
      "\"parties\"\t0.0001004460920268685\r\n",
      "\"outside\"\t0.00010036181761851775\r\n",
      "\"mouth\"\t0.00010033606093706733\r\n",
      "\"remember\"\t0.00010031351374805469\r\n",
      "\"treated\"\t0.00010018121806605929\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 full_mostLeastDenseWords_5.4.1.c\n",
    "#TODO revert order probably"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word density MR stats\n",
    "\n",
    "    ec2_instance_type: m3.xlarge\n",
    "    num_ec2_instances: 15\n",
    "    \n",
    "__Step 1:__ \n",
    "\n",
    "    RUNNING for 649.2s  ~= 10 minutes      \n",
    "    Launched map tasks=190   \n",
    "    Launched reduce tasks=57     \n",
    "\n",
    "__Step 2:__  \n",
    "\n",
    "    RUNNING for 74.4s  ~= 1 minute    \n",
    "    Launched map tasks=110   \n",
    "    Launched reduce tasks=20   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - D. Distribution of 5-gram sizes (character length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing distribution.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile distribution.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class distribution(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.D\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        \n",
    "        char_count = 0\n",
    "        \n",
    "        # Count characters\n",
    "        for word in words:\n",
    "            char_count += len(word)\n",
    "        \n",
    "        yield char_count, 1\n",
    "            \n",
    "    \n",
    "    def combiner(self, ngram_size, counts):\n",
    "        yield ngram_size, sum(count for count in counts)\n",
    "    \n",
    "    def reducer(self, ngram_size, counts):\n",
    "        yield ngram_size, sum(count for count in counts)\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1n',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(\n",
    "                    jobconf=custom_jobconf,\n",
    "                    mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner)\n",
    "        ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.D\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    distribution.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `5.3distributions_test/part-00000': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/distribution.nhaas.20170620.012644.868193\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012644.868193/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob8573237600553353446.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0159\n",
      "  Submitted application application_1497906899862_0159\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0159/\n",
      "  Running job: job_1497906899862_0159\n",
      "  Job job_1497906899862_0159 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0159 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012644.868193/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=45\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=68\n",
      "\t\tFILE: Number of bytes written=400199\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1007\n",
      "\t\tHDFS: Number of bytes written=45\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=42419712\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=18880000\n",
      "\t\tTotal time spent by all map tasks (ms)=27617\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=82851\n",
      "\t\tTotal time spent by all reduce tasks (ms)=7375\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=36875\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=27617\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=7375\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3340\n",
      "\t\tCombine input records=10\n",
      "\t\tCombine output records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=82\n",
      "\t\tInput split bytes=444\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=60\n",
      "\t\tMap output materialized bytes=88\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1904717824\n",
      "\t\tReduce input groups=9\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=9\n",
      "\t\tReduce shuffle bytes=88\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7770181632\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012644.868193/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012644.868193...\n",
      "Removing temp directory /tmp/distribution.nhaas.20170620.012644.868193...\n",
      "WARNING:root:Elapsed time: 65.2790989876 seconds\n",
      "    In minutes: 1.08798498313 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r 5.3distributions_test/part-00000\n",
    "!python distribution.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > 5.3distributions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5 Gram Disttribution on Test Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 65.28 seconds_\n",
    "\n",
    "* _Run time: 1.09 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 563_\n",
    "\n",
    "* _Bytes Written: 45_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 3340_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\t1\r\n",
      "18\t1\r\n",
      "19\t1\r\n",
      "20\t1\r\n",
      "22\t1\r\n",
      "23\t1\r\n",
      "24\t1\r\n",
      "25\t1\r\n",
      "29\t2\r\n"
     ]
    }
   ],
   "source": [
    "!cat 5.3distributions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Histogram 10-line test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+MAAAGuCAYAAAD73ddLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcZWdZJ/DfQ8IyEJZA2ghJOmGJCCrbNNvgCIwIiQph\nZlASEQICGR2ijjIqCJIYEBFnUNmEIAFEISiIhDEsQUEUDKRBtgCBELY2KIFmC6uBZ/64p+FSqeq6\n3V15q7rr+/187qfved/3nPPc+95b1b97zj1V3R0AAABgnKutdwEAAACw2QjjAAAAMJgwDgAAAIMJ\n4wAAADCYMA4AAACDCeMAAAAwmDAOsAlV1XOq6rfWaFtbq+ryqjpoWn5TVT1iLbY9be81VXXyWm1v\nX1XV3arqw9Njvv9617PWquqYquqqOngd9v3QqvrHNdjOb1bVn6xFTftYx3c9lxvttQzA+hLGAQ4w\nVfWxqvpqVX2pqj5fVW+tqp+vqm//zO/un+/uJy64rXvtbkx3f6K7D+nub65B7adX1Z8t2f7x3f2i\nfd32GjojyTOnx/zXSzunDyO+NoX1y6vqot1trKqOraqzq+qyqvriFPSfUVVHXmWPYAO4KkN/dz+5\nu/fqA6GqumdVvbGqvlBVH1um/5ip/ytV9cHV3h9L6rpKXsvLvW/2YVtdVbdYi20BsHvCOMCB6b7d\nfd0kRyd5SpLfSPL8td7Jehw93QCOTnLhKmNOncL6Id19y5UGTaHnbUkuTXL77r5ekrsl+UiSH15h\nnc34nI/05SRnJfm1FfpfmuSfk9woyeOSvLyqtgyqDYADiDAOcADr7i909zlJHpjk5Kr6wSSpqhdW\n1ZOm+4dV1f+bjqLvrKp/qKqrVdWLk2xN8urpCO+vzx3NfHhVfSLJ361whPPmVfX26ejiq6rqhtO+\n7lFVO+Zr3HX0vaqOS/KbSR447e/dU/+3T3uf6np8VX28qj5dVX9aVdef+nbVcXJVfaKqPlNVj5vb\nz52qavt09PnfquppKz1vVfXIqrp4ej7OqaqbTO0fSXKzuefkmvsyP0lOT/KW7v7V7t6RJN396e7+\nw+4+e/45q6rfqKp/TfKCqjp0mrPLqupz0/1vH0mfnrMnTWdFXF5Vr66qG1XVn0+P/4KqOmaRAqvq\n+lX1/Kr6VFX9y7TdXV9JeGhV/WNV/Z+pjo9W1fFz6960qt5cs7M03lBVz5o7gvvm6d/PTzXedW69\nlbb30Kq6ZNreR6vqQSvU/O0jxau9Lpbq7rd394uTXLLMdr8vyR2SnNbdX+3uVyR5b5L/vuBzOf9a\nXu25W/F5X7LNld43u5u3W1TV30/vz89U1cum9l1z8u5pWw9c5HEBsHeEcYBNoLvfnmRHkv+8TPej\np74tSQ7P7D/23d0PTvKJzI6yH9LdT51b5+5JbpXkPivs8iFJfi7JTZJckeTpC9T42iRPTvKyaX+3\nXWbYQ6fbPTMLxYckeeaSMT+c5JZJfjTJE6rqVlP7HyX5o+no882T/MVydVTVf0nyu0l+OsmNk3w8\nydlTjTfPdz8nX1/h4fzuFHLeUlX32M3DvleSV+ymf5fvTXLDzI7Kn5LZ7+8XTMtbk3w1V34eTkzy\n4CRHZPZ4/2la54ZJPpDktAX2myQvymwOb5Hk9knunWT+FPA7J7koyWFJnprk+VVVU99Lkrw9s6PI\np0/17PIj0783mJ7Lf9rd9qrqOpm9jo6fzvr4T0neteBjSFZ+XeyJH0hySXd/aa7t3VP73tjdc7fa\n855kt++b3a3/xCSvT3JokiOTPGPa1q45ue20rZft5eMCYAHCOMDmcWlmQWypf88sdB7d3f/e3f/Q\n3b3Ktk7v7i9391dX6H9xd7+vu7+c5LeS/PRyR/X2woOSPK27L+nuy5M8NsmJ9d1H5X97Omr57syC\n0q5w8u9JblFVh3X35d19/m72cVZ3v3MK249NctdFjyRn9pWAm2UWgs/M7Cj6zVcYe1iSf921UFWn\n1uwMhcur6nlz476V2dHYr0+P7bPd/Yru/soUDH8nsw9I5r2guz/S3V9I8pokH+nuN3T3FUn+MrOA\ntltVdXiS45P8r2m+P53kDzIL+rt8vLufN10z4EWZvZYOr6qtSe6Y5And/Y3u/sck56y2z5W2N/c8\n/GBV/Yfu/lR3r/Z1gXkrvS72xCFJvrCk7QtJrrsX20pWfu4Wed5XtMD6/57ZBzk36e6vTXMDwGDC\nOMDmcUSSncu0/36Si5O8fjoF+DELbOuTe9D/8SRXzyx47qubTNub3/bB+U5YS+bCbZKvZBagkuTh\nSb4vyQen07R/cpF9TKH/s5k9f6vq7rd195em4PyiJG9J8uMrDP9sZgFs17rP7O4bJPnDzJ6zXS7r\n7q/tWqiqa1fVc2t2uv4XMzvl+wZLPvD4t7n7X11m+ZCs7uipjk9NHxJ8Pslzk3zP3JhvP9/d/ZXp\n7iGZPY8759qS1V83K25v+mDngUl+fqrnb6rq+xfY3pW2m+9+XeyJy5Ncb0nb9ZJ8KUnqOxftu3z6\nMGLhmpY8d4s877uz2vq/nqSSvL2qLqyqn1twuwCsIWEcYBOoqjtmFiavdARsCo6P7u6bJblvkl+t\nqh/d1b3CJlc7cn7U3P2tmR2J+0xmF8e69lxdB2V2evyi2700s6Axv+0r8t1Bc1nd/eHuPimzQPJ7\nmV146zqr7WMac6Mk/7LaPlbadWbBZzl/m+S/LbiNeY/O7JTrO0+n3e86vXil/eytTyb5epLDuvsG\n0+163b3IadmfSnLDqrr2XNv862K1ub6S7n5dd/9YZh9gfDDJ81ZZZa1dmORmVTV/JPy2U3vmLtp3\nSHd/Yh/2s6fP+9Lncrfrd/e/dvcju/smSf5HkmeXK6gDDCeMAxzAqup60xHgs5P8WXe/d5kxPzld\n0KmSfDHJN6dbMgu5N9uLXf9sVd16CmJnJHn5dCruh5Jcq6p+oqqunuTxSeYvgvZvSY6puT/DtsRL\nk/xKzS4Mdki+813ZK1YrqKp+tqq2dPe3knx+al7uz7G9JMnDqup2NbtA25OTvK27P7bAPm5QVfep\nqmtV1cHTBcZ+JMnrVljl9CT/uaqeVlVHTNs4LLPv4+/OdTM7uv35ml0cb9Hvf++R7v5UZt8t/r/T\na+lqVXXzqlp6Svxy6348yfYkp1fVNWp2gbb7zg25LLPTzhd6fVXV4VV1v+nDka9ndpR6n/+c3jL7\nuVpVXSuzI8s1zeU1kqS7P5TZ99RPm9r/a5LbZLHv/S9sL57373rfrLZ+Vf1UfeeCf5/LLMzv63se\ngD0kjAMcmF5dVV/K7AjZ45I8LcnDVhh7bJI3ZBZu/inJs7v7TVPf7yZ5/HSq6//eg/2/OMkLMzsN\n91pJfimZXd09yf9M8ieZHWn+cmYXj9vlL6d/P1tV71xmu2dN235zko8m+VqSX1ywpuOSXFhVl2d2\nMbcT50/93qW7/zaz77m/IrOjuzfPgt/VzSzAPSmzoPmZqbb7d/eyf2t8Cnd3yewiWu+e5uwtmR2d\n/63d7OcPk/yHaR/nJ3ntgvXtjYckuUaS92cW3F6euVPrV/GgJHfN7HT8JyV5WWZBetdp2b+T5C3T\n6+suq2zrapmdEXBpZl+3uHtmr6W19iOZfdBxbr5zcbzXz/WfmGRbZs/FU5I8oLsvuwrq2JPnfbn3\nze7Wv2OSt03vhXOS/HJ3f3TqOz3Ji6Y5+em1ezgALFWrX6MHAGDf1exPaH2wu6+SI/kAsD9xZBwA\nuEpU1R2n06OvVrO/h31Ckr9e77oAYCM4ePUhAAB75XuT/FVmF8DbkeQXuvuf17ckANgYnKYOAAAA\ngzlNHQAAAAYTxgEAAGCwDfmd8cMOO6yPOeaY9S4DAAAA9sg73vGOz3T3ltXGbcgwfswxx2T79u3r\nXQYAAADskar6+CLjnKYOAAAAgwnjAAAAMJgwDgAAAIMJ4wAAADCYMA4AAACDCeMAAAAwmDAOAAAA\ngwnjAAAAMJgwDgAAAIMJ4wAAADCYMA4AAACDCeMAAAAw2KphvKqOqqo3VtUHqurCqvrlZcZUVT29\nqi6uqvdU1R3m+k6uqg9Pt5PX+gEAAADA/ubgBcZckeTR3f3OqrpukndU1Xnd/f65MccnOXa63TnJ\nHye5c1XdMMlpSbYl6Wndc7r7c2v6KAAAAGA/suqR8e7+VHe/c7r/pSQfSHLEkmEnJPnTnjk/yQ2q\n6sZJ7pPkvO7eOQXw85Ict6aPAAAAAPYze/Sd8ao6Jsntk7xtSdcRST45t7xjalupHQAAADatRU5T\nT5JU1SFJXpHkf3X3F5d2L7NK76Z9ue2fkuSUJNm6deuiZQEAAOw3jnnM36x3Cfuljz3lJ9a7hDW3\n0JHxqrp6ZkH8z7v7r5YZsiPJUXPLRya5dDftV9LdZ3b3tu7etmXLlkXKAgAAgP3SIldTryTPT/KB\n7n7aCsPOSfKQ6arqd0nyhe7+VJLXJbl3VR1aVYcmuffUBgAAAJvWIqep3y3Jg5O8t6reNbX9ZpKt\nSdLdz0lybpIfT3Jxkq8kedjUt7Oqnpjkgmm9M7p759qVDwAAAPufVcN4d/9jlv/u9/yYTvKoFfrO\nSnLWXlUHAAAAB6A9upo6AAAAsO+EcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAA\ngMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEA\nAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwY\nBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDB\nhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMEOXm1AVZ2V5CeTfLq7f3CZ/l9L8qC57d0qyZbu3llV\nH0vypSTfTHJFd29bq8IBAABgf7XIkfEXJjlupc7u/v3uvl133y7JY5P8fXfvnBtyz6lfEAcAAIAs\nEMa7+81Jdq42bnJSkpfuU0UAAABwgFuz74xX1bUzO4L+irnmTvL6qnpHVZ2yyvqnVNX2qtp+2WWX\nrVVZAAAAsOGs5QXc7pvkLUtOUb9bd98hyfFJHlVVP7LSyt19Zndv6+5tW7ZsWcOyAAAAYGNZyzB+\nYpacot7dl07/fjrJK5PcaQ33BwAAAPulNQnjVXX9JHdP8qq5tutU1XV33U9y7yTvW4v9AQAAwP5s\nkT9t9tIk90hyWFXtSHJakqsnSXc/Zxr2X5O8vru/PLfq4UleWVW79vOS7n7t2pUOAAAA+6dVw3h3\nn7TAmBdm9ifQ5tsuSXLbvS0MAAAADlRr+Z1xAAAAYAHCOAAAAAwmjAMAAMBgwjgAAAAMJowDAADA\nYMI4AAAADCaMAwAAwGDCOAAAAAwmjAMAAMBgwjgAAAAMJowDAADAYMI4AAAADCaMAwAAwGDCOAAA\nAAwmjAMAAMBgwjgAAAAMJowDAADAYMI4AAAADCaMAwAAwGDCOAAAAAwmjAMAAMBgwjgAAAAMJowD\nAADAYMI4AAAADCaMAwAAwGDCOAAAAAwmjAMAAMBgwjgAAAAMJowDAADAYMI4AAAADCaMAwAAwGDC\nOAAAAAwmjAMAAMBgwjgAAAAMJowDAADAYMI4AAAADLZqGK+qs6rq01X1vhX671FVX6iqd023J8z1\nHVdVF1XVxVX1mLUsHAAAAPZXixwZf2GS41YZ8w/dfbvpdkaSVNVBSZ6V5Pgkt05yUlXdel+KBQAA\ngAPBqmG8u9+cZOdebPtOSS7u7ku6+xtJzk5ywl5sBwAAAA4oa/Wd8btW1bur6jVV9QNT2xFJPjk3\nZsfUtqyqOqWqtlfV9ssuu2yNygIAAICNZy3C+DuTHN3dt03yjCR/PbXXMmN7pY1095ndva27t23Z\nsmUNygIAAICNaZ/DeHd/sbsvn+6fm+TqVXVYZkfCj5obemSSS/d1fwAAALC/2+cwXlXfW1U13b/T\ntM3PJrkgybFVddOqukaSE5Ocs6/7AwAAgP3dwasNqKqXJrlHksOqakeS05JcPUm6+zlJHpDkF6rq\niiRfTXJid3eSK6rq1CSvS3JQkrO6+8Kr5FEAAADAfmTVMN7dJ63S/8wkz1yh79wk5+5daQAAAHBg\nWqurqQMAAAALEsYBAABgMGEcAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgMGEc\nAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgMGEcAAAABhPGAQAAYDBhHAAAAAYT\nxgEAAGAwYRwAAAAGE8YBAABgMGEcAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABg\nMGEcAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgMGEcAAAABhPGAQAAYDBhHAAA\nAAYTxgEAAGCwVcN4VZ1VVZ+uqvet0P+gqnrPdHtrVd12ru9jVfXeqnpXVW1fy8IBAABgf7XIkfEX\nJjluN/0fTXL37r5NkicmOXNJ/z27+3bdvW3vSgQAAIADy8GrDejuN1fVMbvpf+vc4vlJjtz3sgAA\nAODAtdbfGX94ktfMLXeS11fVO6rqlDXeFwAAAOyXVj0yvqiqumdmYfyH55rv1t2XVtX3JDmvqj7Y\n3W9eYf1TkpySJFu3bl2rsgAAAGDDWZMj41V1myR/kuSE7v7srvbuvnT699NJXpnkTitto7vP7O5t\n3b1ty5Yta1EWAAAAbEj7HMaramuSv0ry4O7+0Fz7darqurvuJ7l3kmWvyA4AAACbyaqnqVfVS5Pc\nI8lhVbUjyWlJrp4k3f2cJE9IcqMkz66qJLliunL64UleObUdnOQl3f3aq+AxAAAAwH5lkaupn7RK\n/yOSPGKZ9kuS3PbKawAAAMDmttZXUwcAAABWIYwDAADAYMI4AAAADCaMAwAAwGDCOAAAAAwmjAMA\nAMBgwjgAAAAMJowDAADAYMI4AAAADCaMAwAAwGDCOAAAAAwmjAMAAMBgwjgAAAAMJowDAADAYMI4\nAAAADCaMAwAAwGDCOAAAAAwmjAMAAMBgwjgAAAAMJowDAADAYMI4AAAADCaMAwAAwGDCOAAAAAwm\njAMAAMBgwjgAAAAMJowDAADAYMI4AAAADCaMAwAAwGDCOAAAAAwmjAMAAMBgwjgAAAAMJowDAADA\nYMI4AAAADCaMAwAAwGDCOAAAAAwmjAMAAMBgwjgAAAAMtlAYr6qzqurTVfW+Ffqrqp5eVRdX1Xuq\n6g5zfSdX1Yen28lrVTgAAADsrxY9Mv7CJMftpv/4JMdOt1OS/HGSVNUNk5yW5M5J7pTktKo6dG+L\nBQAAgAPBQmG8u9+cZOduhpyQ5E975vwkN6iqGye5T5Lzuntnd38uyXnZfagHAACAA97Ba7SdI5J8\ncm55x9S2UvuVVNUpmR1Vz9atW9eorKveMY/5m/UuYb/0saf8xJpuzzzsHfOwMZiHjcE8bAzmYWMw\nDxuDedgY1noeYJe1uoBbLdPWu2m/cmP3md29rbu3bdmyZY3KAgAAgI1nrcL4jiRHzS0fmeTS3bQD\nAADAprVWYfycJA+Zrqp+lyRf6O5PJXldkntX1aHThdvuPbUBAADAprXQd8ar6qVJ7pHksKrakdkV\n0q+eJN39nCTnJvnxJBcn+UqSh019O6vqiUkumDZ1Rnfv7kJwAAAAcMBbKIx390mr9HeSR63Qd1aS\ns/a8NAAAADgwrdVp6gAAAMCChHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDB\nhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAA\nGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcA\nAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRx\nAAAAGEwYBwAAgMGEcQAAABhsoTBeVcdV1UVVdXFVPWaZ/j+oqndNtw9V1efn+r4513fOWhYPAAAA\n+6ODVxtQVQcleVaSH0uyI8kFVXVOd79/15ju/pW58b+Y5PZzm/hqd99u7UoGAACA/dsiR8bvlOTi\n7r6ku7+R5OwkJ+xm/ElJXroWxQEAAMCBaJEwfkSST84t75jarqSqjk5y0yR/N9d8raraXlXnV9X9\nV9pJVZ0yjdt+2WWXLVAWAAAA7J8WCeO1TFuvMPbEJC/v7m/OtW3t7m1JfibJH1bVzZdbsbvP7O5t\n3b1ty5YtC5QFAAAA+6dFwviOJEfNLR+Z5NIVxp6YJaeod/el07+XJHlTvvv75AAAALDpLBLGL0hy\nbFXdtKqukVngvtJV0avqlkkOTfJPc22HVtU1p/uHJblbkvcvXRcAAAA2k1Wvpt7dV1TVqUlel+Sg\nJGd194VVdUaS7d29K5iflOTs7p4/hf1WSZ5bVd/KLPg/Zf4q7AAAALAZrRrGk6S7z01y7pK2JyxZ\nPn2Z9d6a5If2oT4AAAA44CxymjoAAACwhoRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAY\nTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAA\ngMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEA\nAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwY\nBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYbKEwXlXHVdVFVXVxVT1mmf6HVtVlVfWu6faIub6Tq+rD\n0+3ktSweAAAA9kcHrzagqg5K8qwkP5ZkR5ILquqc7n7/kqEv6+5Tl6x7wySnJdmWpJO8Y1r3c2tS\nPQAAAOyHFjkyfqckF3f3Jd39jSRnJzlhwe3fJ8l53b1zCuDnJTlu70oFAACAA8MiYfyIJJ+cW94x\ntS3136vqPVX18qo6ag/XTVWdUlXbq2r7ZZddtkBZAAAAsH9aJIzXMm29ZPnVSY7p7tskeUOSF+3B\nurPG7jO7e1t3b9uyZcsCZQEAAMD+aZEwviPJUXPLRya5dH5Ad3+2u78+LT4vyX9cdF0AAADYbBYJ\n4xckObaqblpV10hyYpJz5gdU1Y3nFu+X5APT/dcluXdVHVpVhya599QGAAAAm9aqV1Pv7iuq6tTM\nQvRBSc7q7gur6owk27v7nCS/VFX3S3JFkp1JHjqtu7OqnphZoE+SM7p751XwOAAAAGC/sWoYT5Lu\nPjfJuUvanjB3/7FJHrvCumclOWsfagQAAIADyiKnqQMAAABrSBgHAACAwYRxAAAAGEwYBwAAgMGE\ncQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAY\nTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAA\ngMGEcQAAABhMGAcAAIDBhHEAAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBhHEA\nAAAYTBgHAACAwYRxAAAAGEwYBwAAgMGEcQAAABhMGAcAAIDBFgrjVXVcVV1UVRdX1WOW6f/Vqnp/\nVb2nqv62qo6e6/tmVb1rup2zlsUDAADA/ujg1QZU1UFJnpXkx5LsSHJBVZ3T3e+fG/bPSbZ191eq\n6heSPDXJA6e+r3b37da4bgAAANhvLXJk/E5JLu7uS7r7G0nOTnLC/IDufmN3f2VaPD/JkWtbJgAA\nABw4FgnjRyT55NzyjqltJQ9P8pq55WtV1faqOr+q7r8XNQIAAMABZdXT1JPUMm297MCqn02yLcnd\n55q3dvelVXWzJH9XVe/t7o8ss+4pSU5Jkq1bty5QFgAAAOyfFjkyviPJUXPLRya5dOmgqrpXkscl\nuV93f31Xe3dfOv17SZI3Jbn9cjvp7jO7e1t3b9uyZcvCDwAAAAD2N4uE8QuSHFtVN62qayQ5Mcl3\nXRW9qm6f5LmZBfFPz7UfWlXXnO4fluRuSeYv/AYAAACbzqqnqXf3FVV1apLXJTkoyVndfWFVnZFk\ne3efk+T3kxyS5C+rKkk+0d33S3KrJM+tqm9lFvyfsuQq7AAAALDpLPKd8XT3uUnOXdL2hLn791ph\nvbcm+aF9KRAAAAAONIucpg4AAACsIWEcAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YB\nAABgMGEcAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgMGEcAAAABhPGAQAAYDBh\nHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgMGEcAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAG\nE8YBAABgMGEcAAAABhPGAQAAYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgMGEcAAAABhPGAQAA\nYDBhHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgsIXCeFUdV1UXVdXFVfWYZfqvWVUvm/rfVlXHzPU9\ndmq/qKrus3alAwAAwP5p1TBeVQcleVaS45PcOslJVXXrJcMenuRz3X2LJH+Q5PemdW+d5MQkP5Dk\nuCTPnrYHAAAAm9YiR8bvlOTi7r6ku7+R5OwkJywZc0KSF033X57kR6uqpvazu/vr3f3RJBdP2wMA\nAIBNq7p79wOqHpDkuO5+xLT84CR37u5T58a8bxqzY1r+SJI7Jzk9yfnd/WdT+/OTvKa7X77Mfk5J\ncsq0eMskF+3bQxvmsCSfWe8iMA8bhHnYGMzDxmAeNgbzsDGYh43BPGwM5uHAd3R3b1lt0MELbKiW\naVua4FcKrTkAAAAGYklEQVQas8i6s8buM5OcuUA9G0pVbe/ubetdx2ZnHjYG87AxmIeNwTxsDOZh\nYzAPG4N52BjMA7sscpr6jiRHzS0fmeTSlcZU1cFJrp9k54LrAgAAwKaySBi/IMmxVXXTqrpGZhdk\nO2fJmHOSnDzdf0CSv+vZ+e/nJDlxutr6TZMcm+Tta1M6AAAA7J9WPU29u6+oqlOTvC7JQUnO6u4L\nq+qMJNu7+5wkz0/y4qq6OLMj4idO615YVX+R5P1JrkjyqO7+5lX0WNbLfndq/QHKPGwM5mFjMA8b\ng3nYGMzDxmAeNgbzsDGYB5IscAE3AAAAYG0tcpo6AAAAsIaEcQAAABhMGAcAAIDBhHEAAK4yVfU9\n610DwEYkjAPsp6rq+lX1lKr6YFV9drp9YGq7wXrXt1lU1fWq6ner6sVV9TNL+p69XnVtNlX1vVX1\nx1X1rKq6UVWdXlXvraq/qKobr3d9m0VV3XDJ7UZJ3l5Vh1bVDde7vs2iqo6bu3/9qnp+Vb2nql5S\nVYevZ22bSVUdUlVnVNWFVfWFqrqsqs6vqoeud21sDML4HvCLfmOoqm1V9caq+rOqOqqqzpt+wF1Q\nVbdf7/o2C79gNoS/SPK5JPfo7ht1942S3HNq+8t1rWxzeUGSSvKKJCdW1Suq6ppT313Wr6xN54WZ\n/SnVTyZ5Y5KvJvmJJP+Q5DnrV9am85kk75i7bU9yRJJ3TvcZ48lz9/9vkk8luW+SC5I8d10q2pz+\nPMklSe6T5LeTPD3Jg5Pcs6qevLsV2Rz8abM9UFWvTfI3Sa6T5Gcye4O9NMkJSe7V3SesY3mbRlW9\nPclpSW6Q5KlJfqW7X15VP5rkSd1913UtcJOoqlcleWWSNyT56czeF2cneXySf+nu31zH8jaFqrqo\nu2+5p32srap6V3ffbm75cUl+PMn9kpzX3XdYt+I2kar65+6+/XT/E929da7vu+aIq05V/e8k90ry\na9393qnto9190/WtbHOpqnfu+tmzzM8o74dBqurd3X3bueULuvuOVXW1JO/v7u9fx/LYABwZ3zOH\nd/czuvspSW7Q3b/X3Z/o7mckOXq9i9tErt7dr+nulybp7n55Znf+Nsm11re0TeWY7n5hd+/o7qcl\nuV93fzjJw5L8t3WubbP4eFX9+vwph1V1eFX9RmZHBxnjmtN/rJIk3f07Sc5M8uYkN1q3qjaf+f/T\n/OmSvoNGFrKZdff/SfKIJE+oqqdV1XWTOPIz3vdU1a9W1aOTXK+qaq7P///H+XJV/XCSVNV9k+xM\nku7+VmZnVLHJeTPuGb/oN4avVdW9q+qnknRV3T9JquruSb65vqVtKn7BrL8HZhb2/r6qPldVO5O8\nKckNMztbgTFeneS/zDd094uSPDrJN9alos3pVVV1SJJ09+N3NVbVLZJctG5VbULTh7Q/ldnXBc5L\ncu11Lmkzel6S6yY5JMmLkhyWzL5ymeRd61jXZvMLSZ5WVZ9P8htJfilJqmpLkmetZ2FsDE5T3wNV\ndUaSp3b35Uvab5HkKd39gPWpbHOpqttmdnr6t5L8SmY/6E5O8i9JHtndb13H8jaNqrpNkj9J8n1J\n3pfk57r7Q9MvmJO6++nrWuAmUVXfn+TIJOfP/2yqquO6+7XrV9nmMs3DEUnetmQeju/u16xfZZvL\nbubB+2Gg+XnI7EPym3f3+8zDWN4PG0NV3SqzefB7misRxtdIVT2su1+w3nVsduZhYzAPY1TVLyV5\nVJIPJLldkl/u7ldNfd/+viBXrar6xSSnxjysK/OwMfi5tDF4P2wM0/vhfyb5YMwDyzh4vQs4gPx2\nZlfUZX2Zh43BPIzxyCT/sbsvr6pjkry8qo7p7j+KrwqMdErMw0ZgHjYGP5c2Bu+HjeGRSbaZB1Yi\njO+BqnrPSl1J/M3GQczDxmAeNoSDdp3y1t0fq6p7ZPaL/uj4JT+SedgYzMPGYB42BvOwMZgHdksY\n3zOHZ/Z3Aj+3pL2S+J7yOOZhYzAP6+9fq+p23f2uJJk+ef/JJGcl+aH1LW1TMQ8bg3nYGMzDxmAe\nNgbzwG4J43vm/yU5ZNcbal5VvWl8OZuWedgYzMP6e0iSK+YbuvuKJA+pqueuT0mbknnYGMzDxmAe\nNgbzsDGYB3bLBdwAAABgMH9nHAAAAAYTxgEAAGAwYRwAAAAGE8YBAABgMGEcAAAABvv/yMcwUQiV\nWR0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63804c0850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "results_A = []\n",
    "for line in open(\"5.3distributions_test\").readlines():\n",
    "    line = line.strip()\n",
    "    X,Y = line.split(\"\\t\")\n",
    "    results_A.append([int(X),int(Y)])\n",
    "\n",
    "items = (np.array(results_A)[::-1].T)\n",
    "fig = pl.figure(figsize=(17,7))\n",
    "ax = pl.subplot(111)\n",
    "width=0.8\n",
    "ax.bar(range(len(items[0])), items[1], width=width)\n",
    "ax.set_xticks(np.arange(len(items[0])) + width/2)\n",
    "ax.set_xticklabels(items[0], rotation=90)\n",
    "ax.invert_xaxis()\n",
    "\n",
    "\n",
    "pl.title(\"Distributions of 5 Gram lengths in 10-line test\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `full_distribution_5.4.1.d': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/distribution.nhaas.20170620.012753.854016\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012753.854016/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3189912150566476651.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1497906899862_0161\n",
      "  Submitted application application_1497906899862_0161\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0161/\n",
      "  Running job: job_1497906899862_0161\n",
      "  Job job_1497906899862_0161 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0161 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012753.854016/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=619\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=29372\n",
      "\t\tFILE: Number of bytes written=25562613\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=619\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16157466624\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11947520\n",
      "\t\tTotal time spent by all map tasks (ms)=10519184\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31557552\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4667\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=23335\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10519184\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4667\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3964310\n",
      "\t\tCombine input records=58682266\n",
      "\t\tCombine output records=9172\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=75509\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=352088828\n",
      "\t\tMap output materialized bytes=79220\n",
      "\t\tMap output records=58682266\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154677821440\n",
      "\t\tReduce input groups=80\n",
      "\t\tReduce input records=9172\n",
      "\t\tReduce output records=80\n",
      "\t\tReduce shuffle bytes=79220\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=18344\n",
      "\t\tTotal committed heap usage (bytes)=299992875008\n",
      "\t\tVirtual memory (bytes) snapshot=421296168960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012753.854016/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/distribution.nhaas.20170620.012753.854016...\n",
      "Removing temp directory /tmp/distribution.nhaas.20170620.012753.854016...\n",
      "WARNING:root:Elapsed time: 156.667695045 seconds\n",
      "    In minutes: 2.61112825076 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r full_distribution_5.4.1.d\n",
    "!python distribution.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > full_distribution_5.4.1.d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5 Gram Distribution on Full Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 156.67 seconds_\n",
    "\n",
    "* _Run time: 2.61 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 2156069116_\n",
    "\n",
    "* _Bytes Written: 619_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 191_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 3964310_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution MRJob stats\n",
    "\n",
    "__Step 1:__ \n",
    "\n",
    "    RUNNING for 157.8s ~= 2.6 minutes  \n",
    "    Launched map tasks=191  \n",
    "    Launched reduce tasks=16   \n",
    "    \n",
    "__Step 2:__  \n",
    "\n",
    "    RUNNING for 115.0s ~= 2 minutes   \n",
    "    Launched map tasks=139\n",
    "\tLaunched reduce tasks=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/kAAAG1CAYAAACiQDQyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRkKSDwAAACMhyQcAAICRkOQDAADASPw/IFBk1NJO8uYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63a6f56750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "results_A = []\n",
    "for line in open(\"full_distribution_5.4.1.d\").readlines():\n",
    "    line = line.strip()\n",
    "    X,Y = line.split(\"\\t\")\n",
    "    results_A.append([int(X),int(Y)])\n",
    "\n",
    "items = (np.array(results_A)[::-1].T)\n",
    "fig = pl.figure(figsize=(17,7))\n",
    "ax = pl.subplot(111)\n",
    "width=0.8\n",
    "ax.bar(range(len(items[0])), items[1], width=width)\n",
    "ax.set_xticks(np.arange(len(items[0])) + width/2)\n",
    "ax.set_xticklabels(items[0], rotation=90)\n",
    "ax.invert_xaxis()\n",
    "\n",
    "\n",
    "pl.title(\"Distributions of 5 Gram lengths\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.2 <a name=\"5.4.2\"></a>OPTIONAL Question: log-log plots (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Plot the log-log plot of the frequency distributuion of unigrams. Does it follow power law distribution?\n",
    "\n",
    "For more background see:\n",
    "- https://en.wikipedia.org/wiki/Log%E2%80%93log_plot\n",
    "- https://en.wikipedia.org/wiki/Power_law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.5  <a name=\"5.5\"></a> Synonym detection over 2Gig of Data with extra Preprocessing steps (HW5.3 plus some preprocessing)   (Phase 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "For the remainder of this assignment please feel free to eliminate stop words from your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> from nltk.corpus import stopwords\n",
    " stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: A large subset of the Google n-grams dataset as was described above\n",
    "\n",
    "For each HW 5.4 -5.5.1 Please unit test and system test your code with respect \n",
    "to SYSTEMS TEST DATASET and show the results. \n",
    "Please compute the expected answer by hand and show your hand calculations for the \n",
    "SYSTEMS TEST DATASET. Then show the results you get with your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment we will focus on developing methods for detecting synonyms, using the Google 5-grams dataset. At a high level:\n",
    "\n",
    "\n",
    "1. remove stopwords\n",
    "2. get 10,0000 most frequent\n",
    "3. get 1000 (9001-10000) features\n",
    "3. build stripes\n",
    "\n",
    "To accomplish this you must script two main tasks using MRJob:\n",
    "\n",
    "\n",
    "__TASK (1)__ Build stripes for the most frequent 10,000 words using cooccurence information based on\n",
    "the words ranked from 9001,-10,000 as a basis/vocabulary (drop stopword-like terms),\n",
    "and output to a file in your bucket on s3 (bigram analysis, though the words are non-contiguous).\n",
    "\n",
    "\n",
    "__TASK (2)__ Using two (symmetric) comparison methods of your choice \n",
    "(e.g., correlations, distances, similarities), pairwise compare \n",
    "all stripes (vectors), and output to a file in your bucket on s3.\n",
    "\n",
    "#### Design notes for TASK (1)\n",
    "For this task you will be able to modify the pattern we used in HW 3.2\n",
    "(feel free to use the solution as reference). To total the word counts \n",
    "across the 5-grams, output the support from the mappers using the total \n",
    "order inversion pattern:\n",
    "\n",
    "<*word,count>\n",
    "\n",
    "to ensure that the support arrives before the cooccurrences.\n",
    "\n",
    "In addition to ensuring the determination of the total word counts,\n",
    "the mapper must also output co-occurrence counts for the pairs of\n",
    "words inside of each 5-gram. Treat these words as a basket,\n",
    "as we have in HW 3, but count all stripes or pairs in both orders,\n",
    "i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for TASK (2).\n",
    "\n",
    "#### Design notes for _TASK (2)_\n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    "- Jaccard\n",
    "- Cosine similarity\n",
    "- Spearman correlation\n",
    "- Euclidean distance\n",
    "- Taxicab (Manhattan) distance\n",
    "- Shortest path graph distance (a graph, because our data is symmetric!)\n",
    "- Pearson correlation\n",
    "- Kendall correlation\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to\n",
    "parallelize than others, and do not perform more associations than is necessary, \n",
    "since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. \n",
    "\n",
    "Please report the size of the cluster used and the amount of time it takes to run for the index construction task and for the synonym calculation task. How many pairs need to be processed (HINT: use the posting list length to calculate directly)? Report your  Cluster configuration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example MR stats: (report times!)\n",
    "    took ~11 minutes on 5 m3.xlarge nodes\n",
    "    Data-local map tasks=188\n",
    "\tLaunched map tasks=190\n",
    "\tLaunched reduce tasks=15\n",
    "\tOther local map tasks=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE 5.5\n",
    "# ADD OR REMOVE CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Frequency ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing frequencies5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile frequencies5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class frequencies(MRJob):\n",
    "\n",
    "    # START STUDENT CODE 5.4.1.B\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "        \n",
    "    def __init__(self, args):\n",
    "        super(frequencies, self).__init__(args)\n",
    "        #self.min_rank = 9001\n",
    "        #self.max_rank = 10000 \n",
    "        self.current_rank = 0\n",
    "\n",
    "    def configure_options(self): \n",
    "        super(frequencies, self).configure_options() \n",
    "        self.add_passthrough_option('--min_rank', dest='min_rank', type='int', default=9001) \n",
    "        self.add_passthrough_option('--max_rank', dest='max_rank', type='int', default=10000) \n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        # Split line\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        words = splits[0].lower().split()\n",
    "        count = int(splits[1])\n",
    "        \n",
    "        for word in words:\n",
    "            yield word, count\n",
    "            \n",
    "    \n",
    "    def combiner(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield word, total\n",
    "    \n",
    "    def reducer(self, word, counts):\n",
    "        total = sum(count for count in counts)\n",
    "        yield total, word\n",
    "    \n",
    "    def max_reducer(self, count, words):\n",
    "        \n",
    "        # Words come in frequency descending order here\n",
    "        # Only yield the words that are within the min and max frequency ranking desired\n",
    "        \n",
    "        for word in words:\n",
    "            self.current_rank += 1\n",
    "            \n",
    "            if self.current_rank >= self.options.min_rank and self.current_rank <= self.options.max_rank:\n",
    "                yield word, count\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(mapper=self.mapper,\n",
    "                    reducer=self.reducer,\n",
    "                    combiner = self.combiner),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "\n",
    "    # END STUDENT CODE 5.4.1.B\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    frequencies.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency ranking on 10-line test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `frequencies_test5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/frequencies5_5.nhaas.20170620.013034.143683\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013034.143683/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4661398549153768535.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0163\n",
      "  Submitted application application_1497906899862_0163\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0163/\n",
      "  Running job: job_1497906899862_0163\n",
      "  Job job_1497906899862_0163 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0163 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013034.143683/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=357\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=430\n",
      "\t\tFILE: Number of bytes written=400214\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1011\n",
      "\t\tHDFS: Number of bytes written=357\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18700800\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15889920\n",
      "\t\tTotal time spent by all map tasks (ms)=12175\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=36525\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6207\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=31035\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12175\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6207\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2560\n",
      "\t\tCombine input records=50\n",
      "\t\tCombine output records=31\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=94\n",
      "\t\tInput split bytes=448\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=602\n",
      "\t\tMap output materialized bytes=458\n",
      "\t\tMap output records=50\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1908830208\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=31\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=458\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=62\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7742423040\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2868710796068013266.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0164\n",
      "  Submitted application application_1497906899862_0164\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0164/\n",
      "  Running job: job_1497906899862_0164\n",
      "  Job job_1497906899862_0164 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0164 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013034.143683/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=536\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=40\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=396\n",
      "\t\tFILE: Number of bytes written=399541\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=898\n",
      "\t\tHDFS: Number of bytes written=40\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10477056\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14873600\n",
      "\t\tTotal time spent by all map tasks (ms)=6821\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20463\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5810\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29050\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6821\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5810\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2480\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=109\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=385\n",
      "\t\tMap output materialized bytes=437\n",
      "\t\tMap output records=28\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1903898624\n",
      "\t\tReduce input groups=28\n",
      "\t\tReduce input records=28\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=437\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=56\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7757737984\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013034.143683/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013034.143683...\n",
      "Removing temp directory /tmp/frequencies5_5.nhaas.20170620.013034.143683...\n",
      "WARNING:root:Elapsed time: 87.9439299107 seconds\n",
      "    In minutes: 1.46573216518 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r frequencies_test5.5\n",
    "!python frequencies5_5.py --min_rank 2 --max_rank 4 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > frequencies_test5.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Test Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 87.94 seconds_\n",
    "\n",
    "* _Run time: 1.47 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 536_\n",
    "\n",
    "* _Bytes Written: 40_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 2480_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"in\"\t1201\r\n",
      "\"wales\"\t1099\r\n",
      "\"christmas\"\t1099\r\n"
     ]
    }
   ],
   "source": [
    "!cat frequencies_test5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency ranking on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `frequencies5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/frequencies5_5.nhaas.20170620.013204.810165\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013204.810165/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob323669673420398742.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1497906899862_0166\n",
      "  Submitted application application_1497906899862_0166\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0166/\n",
      "  Running job: job_1497906899862_0166\n",
      "  Job job_1497906899862_0166 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 49%\n",
      "   map 100% reduce 61%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0166 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013204.810165/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4158739\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=39013704\n",
      "\t\tFILE: Number of bytes written=138207349\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=4158739\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=44482504704\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=381795840\n",
      "\t\tTotal time spent by all map tasks (ms)=28959964\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=86879892\n",
      "\t\tTotal time spent by all reduce tasks (ms)=149139\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=745695\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=28959964\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=149139\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=15443020\n",
      "\t\tCombine input records=293411330\n",
      "\t\tCombine output records=6822745\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=117613\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=3430141090\n",
      "\t\tMap output materialized bytes=73800744\n",
      "\t\tMap output records=293411330\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154796351488\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=6822745\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=73800744\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13645490\n",
      "\t\tTotal committed heap usage (bytes)=298050387968\n",
      "\t\tVirtual memory (bytes) snapshot=421244661760\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob943523540184338644.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0173\n",
      "  Submitted application application_1497906899862_0173\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0173/\n",
      "  Running job: job_1497906899862_0173\n",
      "  Job job_1497906899862_0173 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0173 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013204.810165/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4176522\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=17944\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2953963\n",
      "\t\tFILE: Number of bytes written=6321850\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4176884\n",
      "\t\tHDFS: Number of bytes written=17944\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=20330496\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=30868480\n",
      "\t\tTotal time spent by all map tasks (ms)=13236\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=39708\n",
      "\t\tTotal time spent by all reduce tasks (ms)=12058\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=60290\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13236\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=12058\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=12860\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=189\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=269339\n",
      "\t\tMap output bytes=4428078\n",
      "\t\tMap output materialized bytes=2969260\n",
      "\t\tMap output records=269339\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1948651520\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=269339\n",
      "\t\tReduce output records=1000\n",
      "\t\tReduce shuffle bytes=2969260\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538678\n",
      "\t\tTotal committed heap usage (bytes)=5218762752\n",
      "\t\tVirtual memory (bytes) snapshot=7753818112\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013204.810165/output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.013204.810165...\n",
      "Removing temp directory /tmp/frequencies5_5.nhaas.20170620.013204.810165...\n",
      "WARNING:root:Elapsed time: 488.209100008 seconds\n",
      "    In minutes: 8.13681833347 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Full Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 477.21 seconds_\n",
    "\n",
    "* _Run time: 8.14 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 2156069116_\n",
    "\n",
    "* _Bytes Written: 4158739_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 191_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 15443020_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"surveys\"\t169333\r\n",
      "\"jungle\"\t169314\r\n",
      "\"lacked\"\t169282\r\n",
      "\"correlate\"\t169273\r\n",
      "\"boxes\"\t169237\r\n",
      "\"escort\"\t169220\r\n",
      "\"disclosed\"\t169132\r\n",
      "\"shepherd\"\t169114\r\n",
      "\"commend\"\t169081\r\n",
      "\"zenith\"\t169049\r\n",
      "\"multiplication\"\t169025\r\n",
      "\"epic\"\t169004\r\n",
      "\"literacy\"\t168967\r\n",
      "\"atonement\"\t168908\r\n",
      "\"soda\"\t168897\r\n",
      "\"necrosis\"\t168894\r\n",
      "\"initially\"\t168891\r\n",
      "\"compounded\"\t168832\r\n",
      "\"compressed\"\t168825\r\n",
      "\"bade\"\t168815\r\n",
      "\"confidential\"\t168713\r\n",
      "\"monitored\"\t168709\r\n",
      "\"residing\"\t168694\r\n",
      "\"shortcomings\"\t168632\r\n",
      "\"disclosure\"\t168627\r\n",
      "\"sulphate\"\t168511\r\n",
      "\"composite\"\t168469\r\n",
      "\"evenly\"\t168458\r\n",
      "\"nephew\"\t168409\r\n",
      "\"canoe\"\t168402\r\n",
      "\"miseries\"\t168377\r\n",
      "\"ethic\"\t168374\r\n",
      "\"cathode\"\t168348\r\n",
      "\"proportionate\"\t168341\r\n",
      "\"treats\"\t168325\r\n",
      "\"speedily\"\t168322\r\n",
      "\"impart\"\t168307\r\n",
      "\"stipulated\"\t168278\r\n",
      "\"hygiene\"\t168271\r\n",
      "\"palestinian\"\t168244\r\n",
      "\"convergence\"\t168145\r\n",
      "\"maxim\"\t168097\r\n",
      "\"schooling\"\t168053\r\n",
      "\"annum\"\t168038\r\n",
      "\"shrink\"\t168034\r\n",
      "\"ribs\"\t167948\r\n",
      "\"recognizes\"\t167929\r\n",
      "\"ridicule\"\t167904\r\n",
      "\"acetic\"\t167850\r\n",
      "\"diminishing\"\t167800\r\n",
      "\"populous\"\t167697\r\n",
      "\"threads\"\t167685\r\n",
      "\"protestants\"\t167678\r\n",
      "\"hailed\"\t167633\r\n",
      "\"completeness\"\t167597\r\n",
      "\"spectators\"\t167553\r\n",
      "\"israelites\"\t167528\r\n",
      "\"lymphocytes\"\t167490\r\n",
      "\"surest\"\t167434\r\n",
      "\"tricks\"\t167353\r\n",
      "\"autosomal\"\t167343\r\n",
      "\"neat\"\t167338\r\n",
      "\"hoc\"\t167228\r\n",
      "\"paces\"\t167196\r\n",
      "\"rigorous\"\t167184\r\n",
      "\"commence\"\t167135\r\n",
      "\"distrust\"\t167132\r\n",
      "\"inferences\"\t167052\r\n",
      "\"brightest\"\t167049\r\n",
      "\"derivatives\"\t167006\r\n",
      "\"honors\"\t166916\r\n",
      "\"lengthy\"\t166744\r\n",
      "\"consulting\"\t166721\r\n",
      "\"hints\"\t166714\r\n",
      "\"practitioner\"\t166632\r\n",
      "\"rushing\"\t166603\r\n",
      "\"aperture\"\t166597\r\n",
      "\"infusion\"\t166594\r\n",
      "\"pleaded\"\t166570\r\n",
      "\"adolescence\"\t166560\r\n",
      "\"allah\"\t166503\r\n",
      "\"trent\"\t166484\r\n",
      "\"thereto\"\t166469\r\n",
      "\"uterine\"\t166422\r\n",
      "\"marriages\"\t166388\r\n",
      "\"defective\"\t166388\r\n",
      "\"structured\"\t166380\r\n",
      "\"slender\"\t166356\r\n",
      "\"disruption\"\t166345\r\n",
      "\"swell\"\t166342\r\n",
      "\"profoundly\"\t166329\r\n",
      "\"fossil\"\t166307\r\n",
      "\"chronological\"\t166300\r\n",
      "\"butt\"\t166297\r\n",
      "\"likened\"\t166273\r\n",
      "\"resembling\"\t166243\r\n",
      "\"ecological\"\t166174\r\n",
      "\"denmark\"\t166148\r\n",
      "\"localized\"\t166144\r\n",
      "\"jones\"\t166118\r\n",
      "\"loading\"\t166105\r\n",
      "\"forthcoming\"\t166037\r\n",
      "\"laser\"\t166027\r\n",
      "\"lt\"\t166027\r\n",
      "\"screening\"\t165948\r\n",
      "\"adopting\"\t165947\r\n",
      "\"employing\"\t165895\r\n",
      "\"preponderance\"\t165842\r\n",
      "\"rs\"\t165728\r\n",
      "\"printer\"\t165606\r\n",
      "\"kicked\"\t165599\r\n",
      "\"occupying\"\t165572\r\n",
      "\"expressive\"\t165541\r\n",
      "\"vogue\"\t165501\r\n",
      "\"balcony\"\t165442\r\n",
      "\"contributors\"\t165414\r\n",
      "\"jackson\"\t165372\r\n",
      "\"scandal\"\t165358\r\n",
      "\"cornea\"\t165335\r\n",
      "\"diversion\"\t165328\r\n",
      "\"investigating\"\t165325\r\n",
      "\"amidst\"\t165313\r\n",
      "\"inhibit\"\t165264\r\n",
      "\"individuality\"\t165261\r\n",
      "\"sterling\"\t165162\r\n",
      "\"funding\"\t165111\r\n",
      "\"cooled\"\t165040\r\n",
      "\"attendant\"\t165029\r\n",
      "\"dismissal\"\t165027\r\n",
      "\"classify\"\t165009\r\n",
      "\"avowed\"\t164983\r\n",
      "\"adviser\"\t164963\r\n",
      "\"bucket\"\t164933\r\n",
      "\"pitched\"\t164927\r\n",
      "\"victories\"\t164832\r\n",
      "\"ceded\"\t164782\r\n",
      "\"restless\"\t164743\r\n",
      "\"narrator\"\t164661\r\n",
      "\"danube\"\t164644\r\n",
      "\"telescope\"\t164633\r\n",
      "\"bidding\"\t164624\r\n",
      "\"careless\"\t164610\r\n",
      "\"discontent\"\t164546\r\n",
      "\"night's\"\t164516\r\n",
      "\"alphabet\"\t164407\r\n",
      "\"robe\"\t164292\r\n",
      "\"remission\"\t164256\r\n",
      "\"ordinances\"\t164246\r\n",
      "\"ink\"\t164202\r\n",
      "\"hasty\"\t164137\r\n",
      "\"statesmen\"\t164110\r\n",
      "\"dumb\"\t164022\r\n",
      "\"subdivided\"\t163907\r\n",
      "\"initiate\"\t163704\r\n",
      "\"futility\"\t163578\r\n",
      "\"adduced\"\t163563\r\n",
      "\"proclaim\"\t163470\r\n",
      "\"interpreter\"\t163384\r\n",
      "\"roses\"\t163306\r\n",
      "\"accumulate\"\t163263\r\n",
      "\"doings\"\t163215\r\n",
      "\"specifications\"\t163140\r\n",
      "\"flashed\"\t163119\r\n",
      "\"revealing\"\t163103\r\n",
      "\"thereafter\"\t163097\r\n",
      "\"lawn\"\t163093\r\n",
      "\"bourgeois\"\t163062\r\n",
      "\"experiencing\"\t163051\r\n",
      "\"pathological\"\t162907\r\n",
      "\"alveolar\"\t162782\r\n",
      "\"unusually\"\t162777\r\n",
      "\"troop\"\t162770\r\n",
      "\"parked\"\t162735\r\n",
      "\"fiery\"\t162714\r\n",
      "\"implementing\"\t162675\r\n",
      "\"insoluble\"\t162668\r\n",
      "\"wording\"\t162667\r\n",
      "\"contradict\"\t162625\r\n",
      "\"buffer\"\t162589\r\n",
      "\"damned\"\t162540\r\n",
      "\"hungary\"\t162461\r\n",
      "\"exhaustion\"\t162460\r\n",
      "\"infringement\"\t162445\r\n",
      "\"essentials\"\t162418\r\n",
      "\"dew\"\t162391\r\n",
      "\"coats\"\t162368\r\n",
      "\"ushered\"\t162358\r\n",
      "\"mast\"\t162347\r\n",
      "\"whither\"\t162335\r\n",
      "\"spoil\"\t162334\r\n",
      "\"altering\"\t162329\r\n",
      "\"unfortunately\"\t162314\r\n",
      "\"agrarian\"\t162300\r\n",
      "\"guides\"\t162297\r\n",
      "\"negation\"\t162147\r\n",
      "\"yielding\"\t162013\r\n",
      "\"sequences\"\t162006\r\n",
      "\"maiden\"\t161915\r\n",
      "\"flourish\"\t161887\r\n",
      "\"traitor\"\t161866\r\n",
      "\"spur\"\t161834\r\n",
      "\"thames\"\t161814\r\n",
      "\"pancreas\"\t161739\r\n",
      "\"deficiencies\"\t161709\r\n",
      "\"inherit\"\t161665\r\n",
      "\"franklin\"\t161630\r\n",
      "\"flush\"\t161538\r\n",
      "\"holocaust\"\t161537\r\n",
      "\"unstable\"\t161450\r\n",
      "\"episodes\"\t161424\r\n",
      "\"redeem\"\t161417\r\n",
      "\"stationary\"\t161322\r\n",
      "\"pilgrims\"\t161315\r\n",
      "\"intrusted\"\t161314\r\n",
      "\"wasting\"\t161307\r\n",
      "\"lobes\"\t161287\r\n",
      "\"dictate\"\t161244\r\n",
      "\"refinement\"\t161231\r\n",
      "\"capitol\"\t161218\r\n",
      "\"articulation\"\t161141\r\n",
      "\"brand\"\t161113\r\n",
      "\"conqueror\"\t161112\r\n",
      "\"inferiority\"\t161097\r\n",
      "\"suggestive\"\t161085\r\n",
      "\"serpent\"\t161018\r\n",
      "\"sued\"\t160892\r\n",
      "\"overlooking\"\t160886\r\n",
      "\"genre\"\t160837\r\n",
      "\"repentance\"\t160812\r\n",
      "\"originate\"\t160798\r\n",
      "\"silly\"\t160760\r\n",
      "\"impatience\"\t160746\r\n",
      "\"centered\"\t160715\r\n",
      "\"whoever\"\t160690\r\n",
      "\"banquet\"\t160663\r\n",
      "\"hinted\"\t160599\r\n",
      "\"localities\"\t160589\r\n",
      "\"deserving\"\t160559\r\n",
      "\"indebtedness\"\t160500\r\n",
      "\"insane\"\t160452\r\n",
      "\"reagan\"\t160450\r\n",
      "\"roofs\"\t160448\r\n",
      "\"grandmother\"\t160442\r\n",
      "\"flocks\"\t160401\r\n",
      "\"spoils\"\t160333\r\n",
      "\"residual\"\t160329\r\n",
      "\"inception\"\t160308\r\n",
      "\"maintains\"\t160244\r\n",
      "\"nova\"\t160225\r\n",
      "\"discrete\"\t160190\r\n",
      "\"expanse\"\t160173\r\n",
      "\"rods\"\t160144\r\n",
      "\"sermons\"\t160110\r\n",
      "\"commandment\"\t160074\r\n",
      "\"bitterly\"\t160070\r\n",
      "\"afterward\"\t160068\r\n",
      "\"operative\"\t159942\r\n",
      "\"revert\"\t159878\r\n",
      "\"analyzing\"\t159811\r\n",
      "\"indicators\"\t159748\r\n",
      "\"habitation\"\t159699\r\n",
      "\"spy\"\t159675\r\n",
      "\"effectually\"\t159674\r\n",
      "\"tribune\"\t159623\r\n",
      "\"confinement\"\t159534\r\n",
      "\"affiliated\"\t159510\r\n",
      "\"vibrations\"\t159501\r\n",
      "\"relish\"\t159487\r\n",
      "\"finishing\"\t159389\r\n",
      "\"punishments\"\t159344\r\n",
      "\"drinks\"\t159320\r\n",
      "\"coronation\"\t159282\r\n",
      "\"cleaned\"\t159279\r\n",
      "\"tv\"\t159194\r\n",
      "\"underestimate\"\t159180\r\n",
      "\"cartilage\"\t159072\r\n",
      "\"ft\"\t159011\r\n",
      "\"wires\"\t158905\r\n",
      "\"crazy\"\t158860\r\n",
      "\"peritoneal\"\t158740\r\n",
      "\"sympathies\"\t158627\r\n",
      "\"rabbit\"\t158582\r\n",
      "\"generic\"\t158539\r\n",
      "\"denoted\"\t158528\r\n",
      "\"licence\"\t158528\r\n",
      "\"endowment\"\t158477\r\n",
      "\"generalization\"\t158456\r\n",
      "\"fallacy\"\t158397\r\n",
      "\"alternate\"\t158384\r\n",
      "\"mate\"\t158378\r\n",
      "\"examinations\"\t158376\r\n",
      "\"myths\"\t158363\r\n",
      "\"sunset\"\t158323\r\n",
      "\"tangible\"\t158279\r\n",
      "\"intervening\"\t158263\r\n",
      "\"abnormalities\"\t158253\r\n",
      "\"amiable\"\t158193\r\n",
      "\"imputed\"\t158166\r\n",
      "\"amply\"\t158157\r\n",
      "\"trapped\"\t158142\r\n",
      "\"commonest\"\t158105\r\n",
      "\"designing\"\t158048\r\n",
      "\"subscribed\"\t158043\r\n",
      "\"arthritis\"\t158020\r\n",
      "\"accusation\"\t157905\r\n",
      "\"diffuse\"\t157857\r\n",
      "\"wax\"\t157767\r\n",
      "\"xiv\"\t157732\r\n",
      "\"detroit\"\t157663\r\n",
      "\"lends\"\t157660\r\n",
      "\"funded\"\t157657\r\n",
      "\"unfamiliar\"\t157650\r\n",
      "\"auxiliary\"\t157641\r\n",
      "\"dreaded\"\t157614\r\n",
      "\"eastward\"\t157543\r\n",
      "\"complexion\"\t157473\r\n",
      "\"decoration\"\t157371\r\n",
      "\"warrior\"\t157357\r\n",
      "\"captive\"\t157317\r\n",
      "\"morphology\"\t157315\r\n",
      "\"flourished\"\t157303\r\n",
      "\"foreground\"\t157190\r\n",
      "\"cage\"\t157134\r\n",
      "\"misfortunes\"\t157066\r\n",
      "\"enmity\"\t157051\r\n",
      "\"suspend\"\t156952\r\n",
      "\"upstairs\"\t156866\r\n",
      "\"tracing\"\t156762\r\n",
      "\"mastered\"\t156755\r\n",
      "\"analysed\"\t156705\r\n",
      "\"rains\"\t156646\r\n",
      "\"unwillingness\"\t156618\r\n",
      "\"packet\"\t156551\r\n",
      "\"admitting\"\t156500\r\n",
      "\"natures\"\t156458\r\n",
      "\"pink\"\t156443\r\n",
      "\"lever\"\t156374\r\n",
      "\"err\"\t156346\r\n",
      "\"clan\"\t156334\r\n",
      "\"extracellular\"\t156329\r\n",
      "\"anonymous\"\t156325\r\n",
      "\"meridian\"\t156288\r\n",
      "\"habitual\"\t156283\r\n",
      "\"benevolent\"\t156244\r\n",
      "\"sketches\"\t156215\r\n",
      "\"charitable\"\t156186\r\n",
      "\"crosses\"\t156156\r\n",
      "\"optimistic\"\t156113\r\n",
      "\"lattice\"\t156108\r\n",
      "\"synthetic\"\t156065\r\n",
      "\"plunge\"\t156060\r\n",
      "\"dearest\"\t156040\r\n",
      "\"excesses\"\t156018\r\n",
      "\"slice\"\t155963\r\n",
      "\"widening\"\t155957\r\n",
      "\"purest\"\t155932\r\n",
      "\"sri\"\t155902\r\n",
      "\"rite\"\t155885\r\n",
      "\"linen\"\t155853\r\n",
      "\"osmotic\"\t155852\r\n",
      "\"bedside\"\t155812\r\n",
      "\"farthest\"\t155791\r\n",
      "\"consul\"\t155653\r\n",
      "\"fare\"\t155620\r\n",
      "\"homer\"\t155560\r\n",
      "\"elevator\"\t155544\r\n",
      "\"versailles\"\t155396\r\n",
      "\"rivalry\"\t155387\r\n",
      "\"waged\"\t155387\r\n",
      "\"pretending\"\t155318\r\n",
      "\"irresistible\"\t155281\r\n",
      "\"judicious\"\t155236\r\n",
      "\"programmes\"\t155209\r\n",
      "\"balls\"\t155204\r\n",
      "\"dielectric\"\t155183\r\n",
      "\"swords\"\t155181\r\n",
      "\"steamer\"\t155152\r\n",
      "\"purview\"\t155146\r\n",
      "\"tuesday\"\t155142\r\n",
      "\"jointly\"\t155126\r\n",
      "\"colonization\"\t155125\r\n",
      "\"architectural\"\t155086\r\n",
      "\"fascination\"\t155003\r\n",
      "\"tumult\"\t154967\r\n",
      "\"officially\"\t154967\r\n",
      "\"cleft\"\t154963\r\n",
      "\"synod\"\t154916\r\n",
      "\"unprecedented\"\t154914\r\n",
      "\"skeletal\"\t154913\r\n",
      "\"questioning\"\t154890\r\n",
      "\"cons\"\t154884\r\n",
      "\"mitral\"\t154844\r\n",
      "\"sweeping\"\t154808\r\n",
      "\"sanitary\"\t154807\r\n",
      "\"marching\"\t154765\r\n",
      "\"perimeter\"\t154640\r\n",
      "\"shareholders\"\t154566\r\n",
      "\"damp\"\t154441\r\n",
      "\"aversion\"\t154377\r\n",
      "\"phosphorus\"\t154374\r\n",
      "\"residential\"\t154336\r\n",
      "\"avoidance\"\t154311\r\n",
      "\"cart\"\t154290\r\n",
      "\"wholesale\"\t154269\r\n",
      "\"brother's\"\t154225\r\n",
      "\"entropy\"\t154172\r\n",
      "\"impacts\"\t154170\r\n",
      "\"firmness\"\t154163\r\n",
      "\"wills\"\t154083\r\n",
      "\"careers\"\t154051\r\n",
      "\"interpersonal\"\t153983\r\n",
      "\"inmates\"\t153934\r\n",
      "\"commonplace\"\t153829\r\n",
      "\"contradictory\"\t153825\r\n",
      "\"groundwork\"\t153793\r\n",
      "\"graceful\"\t153721\r\n",
      "\"hearth\"\t153691\r\n",
      "\"violating\"\t153588\r\n",
      "\"buenos\"\t153560\r\n",
      "\"approximated\"\t153559\r\n",
      "\"weep\"\t153556\r\n",
      "\"informing\"\t153542\r\n",
      "\"pores\"\t153522\r\n",
      "\"hundredth\"\t153513\r\n",
      "\"ether\"\t153511\r\n",
      "\"sabha\"\t153474\r\n",
      "\"obscured\"\t153473\r\n",
      "\"hungarian\"\t153428\r\n",
      "\"oblige\"\t153425\r\n",
      "\"shouts\"\t153335\r\n",
      "\"vicissitudes\"\t153223\r\n",
      "\"awaken\"\t153207\r\n",
      "\"politically\"\t153205\r\n",
      "\"hue\"\t153127\r\n",
      "\"digestion\"\t153125\r\n",
      "\"americas\"\t153124\r\n",
      "\"curb\"\t153108\r\n",
      "\"barbarous\"\t153100\r\n",
      "\"debated\"\t152990\r\n",
      "\"sinner\"\t152989\r\n",
      "\"presumably\"\t152894\r\n",
      "\"alaska\"\t152850\r\n",
      "\"foe\"\t152840\r\n",
      "\"recollections\"\t152755\r\n",
      "\"sack\"\t152743\r\n",
      "\"repaid\"\t152737\r\n",
      "\"amazement\"\t152730\r\n",
      "\"prussian\"\t152722\r\n",
      "\"pyramid\"\t152684\r\n",
      "\"voyages\"\t152671\r\n",
      "\"bombing\"\t152661\r\n",
      "\"kinship\"\t152648\r\n",
      "\"filtered\"\t152622\r\n",
      "\"temperament\"\t152621\r\n",
      "\"collateral\"\t152607\r\n",
      "\"relaxed\"\t152602\r\n",
      "\"transitional\"\t152577\r\n",
      "\"energetic\"\t152565\r\n",
      "\"paradigm\"\t152562\r\n",
      "\"psychoanalytic\"\t152515\r\n",
      "\"forts\"\t152483\r\n",
      "\"enriched\"\t152475\r\n",
      "\"advertisement\"\t152449\r\n",
      "\"ie\"\t152372\r\n",
      "\"doctor's\"\t152368\r\n",
      "\"floors\"\t152311\r\n",
      "\"offerings\"\t152271\r\n",
      "\"vault\"\t152216\r\n",
      "\"expects\"\t152195\r\n",
      "\"distressed\"\t152148\r\n",
      "\"tore\"\t152142\r\n",
      "\"oblique\"\t152139\r\n",
      "\"holdings\"\t152133\r\n",
      "\"ugly\"\t152130\r\n",
      "\"discerned\"\t152117\r\n",
      "\"mould\"\t152086\r\n",
      "\"immunities\"\t152072\r\n",
      "\"gentry\"\t152066\r\n",
      "\"elapse\"\t152037\r\n",
      "\"logically\"\t151994\r\n",
      "\"catalog\"\t151989\r\n",
      "\"stead\"\t151963\r\n",
      "\"renounce\"\t151923\r\n",
      "\"scarlet\"\t151885\r\n",
      "\"clearance\"\t151851\r\n",
      "\"chimney\"\t151846\r\n",
      "\"honestly\"\t151766\r\n",
      "\"assisting\"\t151702\r\n",
      "\"inflict\"\t151593\r\n",
      "\"faction\"\t151569\r\n",
      "\"spake\"\t151532\r\n",
      "\"designer\"\t151438\r\n",
      "\"placenta\"\t151374\r\n",
      "\"impending\"\t151371\r\n",
      "\"practitioners\"\t151281\r\n",
      "\"realms\"\t151280\r\n",
      "\"sadness\"\t151260\r\n",
      "\"ashore\"\t151242\r\n",
      "\"unconstitutional\"\t151234\r\n",
      "\"jane\"\t151227\r\n",
      "\"flexor\"\t151201\r\n",
      "\"fairness\"\t151201\r\n",
      "\"scholarly\"\t151198\r\n",
      "\"nuisance\"\t151165\r\n",
      "\"humidity\"\t151142\r\n",
      "\"switzerland\"\t151079\r\n",
      "\"adversely\"\t151078\r\n",
      "\"feathers\"\t151006\r\n",
      "\"pleas\"\t150994\r\n",
      "\"inauguration\"\t150960\r\n",
      "\"offend\"\t150922\r\n",
      "\"superstition\"\t150891\r\n",
      "\"tents\"\t150863\r\n",
      "\"universality\"\t150841\r\n",
      "\"logarithm\"\t150747\r\n",
      "\"conveying\"\t150741\r\n",
      "\"preside\"\t150675\r\n",
      "\"unchanged\"\t150654\r\n",
      "\"clues\"\t150630\r\n",
      "\"shy\"\t150556\r\n",
      "\"secrecy\"\t150526\r\n",
      "\"hymn\"\t150448\r\n",
      "\"metropolis\"\t150403\r\n",
      "\"captains\"\t150346\r\n",
      "\"polished\"\t150340\r\n",
      "\"formative\"\t150290\r\n",
      "\"purport\"\t150287\r\n",
      "\"lobby\"\t150286\r\n",
      "\"secreted\"\t150283\r\n",
      "\"probe\"\t150280\r\n",
      "\"drained\"\t150272\r\n",
      "\"worldly\"\t150265\r\n",
      "\"examines\"\t150254\r\n",
      "\"twist\"\t150180\r\n",
      "\"prosecuted\"\t150152\r\n",
      "\"imf\"\t150136\r\n",
      "\"inspector\"\t150098\r\n",
      "\"alpha\"\t150080\r\n",
      "\"environments\"\t150047\r\n",
      "\"sensibility\"\t150023\r\n",
      "\"believers\"\t149889\r\n",
      "\"demonstrating\"\t149866\r\n",
      "\"deduce\"\t149839\r\n",
      "\"congestive\"\t149833\r\n",
      "\"dame\"\t149819\r\n",
      "\"groove\"\t149806\r\n",
      "\"instructor\"\t149798\r\n",
      "\"marking\"\t149792\r\n",
      "\"postoperative\"\t149784\r\n",
      "\"defenders\"\t149704\r\n",
      "\"contamination\"\t149593\r\n",
      "\"whip\"\t149567\r\n",
      "\"pierced\"\t149518\r\n",
      "\"transplantation\"\t149494\r\n",
      "\"shoe\"\t149379\r\n",
      "\"recreation\"\t149322\r\n",
      "\"vastly\"\t149315\r\n",
      "\"illusions\"\t149307\r\n",
      "\"backwards\"\t149296\r\n",
      "\"poorly\"\t149289\r\n",
      "\"forfeited\"\t149252\r\n",
      "\"softly\"\t149245\r\n",
      "\"arches\"\t149234\r\n",
      "\"apartments\"\t149188\r\n",
      "\"sticking\"\t149165\r\n",
      "\"emblem\"\t149109\r\n",
      "\"gratify\"\t149077\r\n",
      "\"efficiently\"\t148993\r\n",
      "\"plentiful\"\t148967\r\n",
      "\"shells\"\t148829\r\n",
      "\"counseling\"\t148824\r\n",
      "\"necks\"\t148730\r\n",
      "\"acknowledgments\"\t148699\r\n",
      "\"magnificence\"\t148694\r\n",
      "\"graces\"\t148689\r\n",
      "\"enforcing\"\t148688\r\n",
      "\"regeneration\"\t148654\r\n",
      "\"mobilization\"\t148643\r\n",
      "\"codes\"\t148541\r\n",
      "\"maxillary\"\t148523\r\n",
      "\"painters\"\t148512\r\n",
      "\"dilatation\"\t148506\r\n",
      "\"metaphysical\"\t148472\r\n",
      "\"imbued\"\t148407\r\n",
      "\"pipes\"\t148340\r\n",
      "\"defender\"\t148300\r\n",
      "\"thinkers\"\t148291\r\n",
      "\"cognizance\"\t148283\r\n",
      "\"disposing\"\t148258\r\n",
      "\"mind's\"\t148233\r\n",
      "\"overcoming\"\t148165\r\n",
      "\"endeavouring\"\t148143\r\n",
      "\"cunning\"\t148096\r\n",
      "\"impair\"\t148079\r\n",
      "\"testified\"\t148071\r\n",
      "\"dementia\"\t148069\r\n",
      "\"bottles\"\t148064\r\n",
      "\"southeastern\"\t148050\r\n",
      "\"resolving\"\t148024\r\n",
      "\"gaza\"\t147988\r\n",
      "\"narrower\"\t147969\r\n",
      "\"humane\"\t147920\r\n",
      "\"priesthood\"\t147903\r\n",
      "\"parks\"\t147889\r\n",
      "\"aggravated\"\t147856\r\n",
      "\"continuously\"\t147837\r\n",
      "\"terminology\"\t147830\r\n",
      "\"favorably\"\t147789\r\n",
      "\"ce\"\t147755\r\n",
      "\"substantive\"\t147746\r\n",
      "\"learner\"\t147594\r\n",
      "\"flourishing\"\t147557\r\n",
      "\"rating\"\t147526\r\n",
      "\"ills\"\t147457\r\n",
      "\"beset\"\t147453\r\n",
      "\"polymer\"\t147422\r\n",
      "\"knocking\"\t147394\r\n",
      "\"bacon\"\t147380\r\n",
      "\"penetrating\"\t147345\r\n",
      "\"axe\"\t147295\r\n",
      "\"kindred\"\t147274\r\n",
      "\"incur\"\t147260\r\n",
      "\"da\"\t147231\r\n",
      "\"crucified\"\t147213\r\n",
      "\"gravel\"\t147142\r\n",
      "\"sheath\"\t147129\r\n",
      "\"viceroy\"\t147099\r\n",
      "\"attested\"\t147072\r\n",
      "\"demographic\"\t147052\r\n",
      "\"eliminating\"\t147048\r\n",
      "\"thereon\"\t147010\r\n",
      "\"assemblies\"\t147008\r\n",
      "\"iran\"\t147005\r\n",
      "\"singapore\"\t146918\r\n",
      "\"occurrences\"\t146877\r\n",
      "\"predicting\"\t146861\r\n",
      "\"electorate\"\t146822\r\n",
      "\"barred\"\t146821\r\n",
      "\"postpone\"\t146808\r\n",
      "\"sequel\"\t146804\r\n",
      "\"darker\"\t146781\r\n",
      "\"rudiments\"\t146779\r\n",
      "\"schizophrenia\"\t146741\r\n",
      "\"est\"\t146713\r\n",
      "\"hay\"\t146673\r\n",
      "\"liverpool\"\t146663\r\n",
      "\"purified\"\t146561\r\n",
      "\"counteract\"\t146493\r\n",
      "\"eagle\"\t146480\r\n",
      "\"sunny\"\t146460\r\n",
      "\"darkest\"\t146323\r\n",
      "\"dishes\"\t146274\r\n",
      "\"knelt\"\t146221\r\n",
      "\"inventor\"\t146210\r\n",
      "\"diplomacy\"\t146167\r\n",
      "\"cane\"\t146155\r\n",
      "\"awaiting\"\t146152\r\n",
      "\"brunt\"\t146071\r\n",
      "\"enumerated\"\t146027\r\n",
      "\"authoritative\"\t146017\r\n",
      "\"soundness\"\t145987\r\n",
      "\"peru\"\t145983\r\n",
      "\"consonant\"\t145913\r\n",
      "\"spherical\"\t145887\r\n",
      "\"opium\"\t145865\r\n",
      "\"jar\"\t145849\r\n",
      "\"imagery\"\t145821\r\n",
      "\"intolerable\"\t145815\r\n",
      "\"entitle\"\t145750\r\n",
      "\"defines\"\t145702\r\n",
      "\"percentages\"\t145698\r\n",
      "\"commensurate\"\t145688\r\n",
      "\"parallels\"\t145674\r\n",
      "\"governance\"\t145658\r\n",
      "\"loosely\"\t145651\r\n",
      "\"denies\"\t145624\r\n",
      "\"streaming\"\t145605\r\n",
      "\"backing\"\t145553\r\n",
      "\"backbone\"\t145527\r\n",
      "\"anglican\"\t145511\r\n",
      "\"disparity\"\t145499\r\n",
      "\"calamity\"\t145441\r\n",
      "\"suspicions\"\t145375\r\n",
      "\"labourers\"\t145373\r\n",
      "\"ieee\"\t145348\r\n",
      "\"frustrated\"\t145333\r\n",
      "\"accompaniment\"\t145279\r\n",
      "\"intricate\"\t145248\r\n",
      "\"pernicious\"\t145247\r\n",
      "\"belgium\"\t145155\r\n",
      "\"entities\"\t145104\r\n",
      "\"diamond\"\t145100\r\n",
      "\"wept\"\t145070\r\n",
      "\"stack\"\t145040\r\n",
      "\"imperfections\"\t144999\r\n",
      "\"delivering\"\t144955\r\n",
      "\"questionable\"\t144954\r\n",
      "\"terminals\"\t144945\r\n",
      "\"concede\"\t144922\r\n",
      "\"trigger\"\t144908\r\n",
      "\"synonymous\"\t144867\r\n",
      "\"flatter\"\t144861\r\n",
      "\"leaped\"\t144846\r\n",
      "\"halfway\"\t144790\r\n",
      "\"tourism\"\t144753\r\n",
      "\"puzzle\"\t144721\r\n",
      "\"predecessor\"\t144647\r\n",
      "\"contending\"\t144569\r\n",
      "\"modernization\"\t144564\r\n",
      "\"atrophy\"\t144548\r\n",
      "\"restructuring\"\t144482\r\n",
      "\"unnatural\"\t144472\r\n",
      "\"annoyed\"\t144470\r\n",
      "\"copying\"\t144468\r\n",
      "\"broadest\"\t144415\r\n",
      "\"fog\"\t144370\r\n",
      "\"coating\"\t144342\r\n",
      "\"durable\"\t144323\r\n",
      "\"desperately\"\t144273\r\n",
      "\"blocked\"\t144235\r\n",
      "\"elegance\"\t144221\r\n",
      "\"economists\"\t144192\r\n",
      "\"strenuous\"\t144187\r\n",
      "\"secretaries\"\t144174\r\n",
      "\"statues\"\t144112\r\n",
      "\"bulb\"\t144065\r\n",
      "\"comic\"\t144047\r\n",
      "\"acutely\"\t143953\r\n",
      "\"fuss\"\t143927\r\n",
      "\"chord\"\t143860\r\n",
      "\"captivity\"\t143858\r\n",
      "\"travellers\"\t143847\r\n",
      "\"uppermost\"\t143805\r\n",
      "\"despise\"\t143734\r\n",
      "\"babies\"\t143731\r\n",
      "\"frost\"\t143717\r\n",
      "\"countess\"\t143672\r\n",
      "\"relic\"\t143652\r\n",
      "\"vietnamese\"\t143643\r\n",
      "\"pleases\"\t143629\r\n",
      "\"ovary\"\t143615\r\n",
      "\"consultant\"\t143593\r\n",
      "\"viral\"\t143576\r\n",
      "\"woven\"\t143459\r\n",
      "\"clergyman\"\t143407\r\n",
      "\"madras\"\t143391\r\n",
      "\"inquisition\"\t143388\r\n",
      "\"steering\"\t143376\r\n",
      "\"canons\"\t143375\r\n",
      "\"battalion\"\t143369\r\n",
      "\"socioeconomic\"\t143361\r\n",
      "\"ship's\"\t143357\r\n",
      "\"staple\"\t143354\r\n",
      "\"precincts\"\t143324\r\n",
      "\"dissociation\"\t143281\r\n",
      "\"arduous\"\t143199\r\n",
      "\"glowing\"\t143176\r\n",
      "\"hampered\"\t143142\r\n",
      "\"synagogue\"\t143106\r\n",
      "\"matthew\"\t143098\r\n",
      "\"realizes\"\t143081\r\n",
      "\"marshall\"\t143059\r\n",
      "\"crystalline\"\t143040\r\n",
      "\"linguistics\"\t143038\r\n",
      "\"anesthesia\"\t143004\r\n",
      "\"practise\"\t142912\r\n",
      "\"horseback\"\t142818\r\n",
      "\"summon\"\t142803\r\n",
      "\"herds\"\t142798\r\n",
      "\"eruption\"\t142783\r\n",
      "\"restrictive\"\t142780\r\n",
      "\"specialist\"\t142763\r\n",
      "\"plexus\"\t142689\r\n",
      "\"precarious\"\t142681\r\n",
      "\"athenians\"\t142667\r\n",
      "\"rejoiced\"\t142654\r\n",
      "\"precursor\"\t142625\r\n",
      "\"sticks\"\t142568\r\n",
      "\"vigilance\"\t142541\r\n",
      "\"provoke\"\t142518\r\n",
      "\"accent\"\t142508\r\n",
      "\"recipients\"\t142500\r\n",
      "\"actuated\"\t142486\r\n",
      "\"viewing\"\t142462\r\n",
      "\"merciful\"\t142453\r\n",
      "\"authorship\"\t142448\r\n",
      "\"mystical\"\t142447\r\n",
      "\"abyss\"\t142437\r\n",
      "\"turmoil\"\t142428\r\n",
      "\"subcutaneous\"\t142382\r\n",
      "\"radioactive\"\t142368\r\n",
      "\"insensible\"\t142243\r\n",
      "\"nationals\"\t142149\r\n",
      "\"appropriateness\"\t142113\r\n",
      "\"spelling\"\t142098\r\n",
      "\"repression\"\t142095\r\n",
      "\"alzheimer's\"\t142085\r\n",
      "\"violently\"\t142069\r\n",
      "\"marrying\"\t142067\r\n",
      "\"pursuits\"\t142039\r\n",
      "\"tray\"\t142032\r\n",
      "\"scrap\"\t142028\r\n",
      "\"concur\"\t141984\r\n",
      "\"sinners\"\t141936\r\n",
      "\"trademark\"\t141926\r\n",
      "\"fulfilling\"\t141919\r\n",
      "\"milton\"\t141908\r\n",
      "\"factions\"\t141903\r\n",
      "\"southward\"\t141896\r\n",
      "\"arabian\"\t141878\r\n",
      "\"avenge\"\t141840\r\n",
      "\"controversies\"\t141834\r\n",
      "\"uniqueness\"\t141818\r\n",
      "\"miraculous\"\t141802\r\n",
      "\"sanctioned\"\t141761\r\n",
      "\"mutations\"\t141756\r\n",
      "\"extravagant\"\t141752\r\n",
      "\"permitting\"\t141749\r\n",
      "\"distributions\"\t141704\r\n",
      "\"anemia\"\t141669\r\n",
      "\"transparent\"\t141576\r\n",
      "\"conditional\"\t141575\r\n",
      "\"polarization\"\t141571\r\n",
      "\"shrewd\"\t141510\r\n",
      "\"antiquities\"\t141439\r\n",
      "\"highways\"\t141423\r\n",
      "\"delights\"\t141415\r\n",
      "\"lighting\"\t141403\r\n",
      "\"relies\"\t141382\r\n",
      "\"surround\"\t141366\r\n",
      "\"experimentally\"\t141346\r\n",
      "\"ferdinand\"\t141339\r\n",
      "\"potentials\"\t141331\r\n",
      "\"reprint\"\t141330\r\n",
      "\"harmonious\"\t141328\r\n",
      "\"thoughtful\"\t141321\r\n",
      "\"hymns\"\t141227\r\n",
      "\"replacing\"\t141197\r\n",
      "\"incubation\"\t141145\r\n",
      "\"enumeration\"\t141070\r\n",
      "\"appointments\"\t141067\r\n",
      "\"notification\"\t141051\r\n",
      "\"warmer\"\t141005\r\n",
      "\"avert\"\t140973\r\n",
      "\"autobiography\"\t140944\r\n",
      "\"nationalist\"\t140942\r\n",
      "\"subsidiary\"\t140836\r\n",
      "\"accepts\"\t140802\r\n",
      "\"lamps\"\t140793\r\n",
      "\"plaintiffs\"\t140762\r\n",
      "\"atrium\"\t140759\r\n",
      "\"articular\"\t140728\r\n",
      "\"deliberations\"\t140721\r\n",
      "\"postulated\"\t140705\r\n",
      "\"housed\"\t140683\r\n",
      "\"esophagus\"\t140673\r\n",
      "\"frankly\"\t140616\r\n",
      "\"preparatory\"\t140605\r\n",
      "\"anarchy\"\t140576\r\n",
      "\"campaigns\"\t140574\r\n",
      "\"distracted\"\t140543\r\n",
      "\"testator\"\t140496\r\n",
      "\"troublesome\"\t140437\r\n",
      "\"dryness\"\t140413\r\n",
      "\"binds\"\t140398\r\n",
      "\"fide\"\t140358\r\n",
      "\"orient\"\t140346\r\n",
      "\"indiana\"\t140336\r\n",
      "\"predominance\"\t140334\r\n",
      "\"forcibly\"\t140303\r\n",
      "\"allude\"\t140282\r\n",
      "\"vomiting\"\t140239\r\n",
      "\"cheese\"\t140235\r\n",
      "\"traversed\"\t140187\r\n",
      "\"interrupt\"\t140174\r\n",
      "\"workplace\"\t140133\r\n",
      "\"armistice\"\t140086\r\n",
      "\"merged\"\t140083\r\n",
      "\"qui\"\t140029\r\n",
      "\"canals\"\t140002\r\n",
      "\"nursery\"\t139999\r\n",
      "\"illustrating\"\t139964\r\n",
      "\"domains\"\t139933\r\n",
      "\"trembled\"\t139766\r\n",
      "\"murderer\"\t139732\r\n",
      "\"fibrous\"\t139659\r\n",
      "\"usages\"\t139639\r\n",
      "\"unrelated\"\t139637\r\n",
      "\"freshness\"\t139570\r\n",
      "\"interim\"\t139562\r\n",
      "\"glasgow\"\t139537\r\n",
      "\"henceforth\"\t139531\r\n",
      "\"displeasure\"\t139511\r\n",
      "\"douglas\"\t139478\r\n",
      "\"neighbour\"\t139475\r\n",
      "\"administering\"\t139447\r\n",
      "\"clubs\"\t139409\r\n",
      "\"downs\"\t139401\r\n",
      "\"martyrs\"\t139375\r\n",
      "\"politic\"\t139346\r\n",
      "\"humiliation\"\t139256\r\n",
      "\"whigs\"\t139236\r\n",
      "\"arkansas\"\t139209\r\n",
      "\"appellate\"\t139167\r\n",
      "\"broadcasting\"\t139141\r\n",
      "\"traders\"\t139077\r\n",
      "\"ulnar\"\t139017\r\n",
      "\"turbulent\"\t138963\r\n",
      "\"accrue\"\t138937\r\n",
      "\"uric\"\t138935\r\n",
      "\"odor\"\t138869\r\n",
      "\"grandson\"\t138811\r\n",
      "\"establishments\"\t138764\r\n",
      "\"metallic\"\t138734\r\n",
      "\"predicate\"\t138715\r\n",
      "\"amuse\"\t138683\r\n",
      "\"twisted\"\t138670\r\n",
      "\"movies\"\t138666\r\n",
      "\"confided\"\t138643\r\n",
      "\"ganglion\"\t138618\r\n",
      "\"oaths\"\t138599\r\n",
      "\"sherman\"\t138594\r\n",
      "\"dysfunction\"\t138588\r\n",
      "\"provoked\"\t138585\r\n",
      "\"asserts\"\t138581\r\n",
      "\"uptake\"\t138564\r\n",
      "\"alternating\"\t138520\r\n",
      "\"attaches\"\t138510\r\n",
      "\"syntax\"\t138455\r\n",
      "\"transcription\"\t138443\r\n",
      "\"simplify\"\t138432\r\n",
      "\"sayings\"\t138427\r\n",
      "\"targets\"\t138421\r\n",
      "\"intrusion\"\t138407\r\n",
      "\"bees\"\t138387\r\n",
      "\"discomfort\"\t138372\r\n",
      "\"insists\"\t138371\r\n",
      "\"lutheran\"\t138321\r\n",
      "\"tribal\"\t138289\r\n",
      "\"hebrews\"\t138272\r\n",
      "\"inspect\"\t138265\r\n",
      "\"terrors\"\t138162\r\n",
      "\"diabetic\"\t138149\r\n",
      "\"recruited\"\t138124\r\n",
      "\"individually\"\t138104\r\n",
      "\"dietary\"\t138089\r\n",
      "\"constancy\"\t137935\r\n",
      "\"lag\"\t137811\r\n",
      "\"solemnity\"\t137796\r\n",
      "\"masculine\"\t137779\r\n",
      "\"undergraduate\"\t137714\r\n",
      "\"relinquish\"\t137662\r\n",
      "\"dividend\"\t137592\r\n",
      "\"numerator\"\t137561\r\n",
      "\"survivor\"\t137546\r\n",
      "\"carpet\"\t137543\r\n",
      "\"despatch\"\t137520\r\n",
      "\"remotest\"\t137491\r\n",
      "\"executor\"\t137485\r\n",
      "\"drafted\"\t137479\r\n",
      "\"sac\"\t137467\r\n",
      "\"trademarks\"\t137430\r\n",
      "\"weakest\"\t137393\r\n",
      "\"explanatory\"\t137390\r\n",
      "\"randomly\"\t137372\r\n",
      "\"disproportionate\"\t137295\r\n",
      "\"extant\"\t137282\r\n",
      "\"confuse\"\t137225\r\n",
      "\"skins\"\t137211\r\n",
      "\"faded\"\t137180\r\n",
      "\"kin\"\t137158\r\n",
      "\"crowns\"\t137099\r\n",
      "\"purchases\"\t137087\r\n",
      "\"articulate\"\t137062\r\n",
      "\"illuminated\"\t137053\r\n",
      "\"laden\"\t137035\r\n",
      "\"performances\"\t136995\r\n",
      "\"comprehended\"\t136955\r\n",
      "\"hangs\"\t136952\r\n",
      "\"despised\"\t136909\r\n",
      "\"commissions\"\t136900\r\n",
      "\"sandy\"\t136871\r\n",
      "\"weighing\"\t136796\r\n",
      "\"au\"\t136773\r\n",
      "\"barren\"\t136703\r\n",
      "\"superfluous\"\t136700\r\n",
      "\"excitation\"\t136695\r\n",
      "\"believeth\"\t136682\r\n",
      "\"bounty\"\t136682\r\n",
      "\"amplifier\"\t136597\r\n",
      "\"prolong\"\t136584\r\n",
      "\"fortified\"\t136560\r\n",
      "\"lodging\"\t136556\r\n",
      "\"hydroxide\"\t136545\r\n",
      "\"falsehood\"\t136536\r\n",
      "\"ammonium\"\t136534\r\n",
      "\"remembering\"\t136499\r\n",
      "\"immigrant\"\t136497\r\n",
      "\"consuming\"\t136481\r\n",
      "\"kashmir\"\t136479\r\n"
     ]
    }
   ],
   "source": [
    "!cat frequencies5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stripes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stripes5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stripes5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import itertools\n",
    "import collections\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class stripes(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_STRIPES\n",
    "  \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.valid_words = set()\n",
    "        super(stripes, self).__init__(args)\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        # Load the left table in the init so all mappers get this info\n",
    "        with open(\"frequencies5.5\", 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                x = line.strip().split(\"\\t\")\n",
    "                self.valid_words.add(x[0].strip(\"\\\"\"))\n",
    "            \n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        splits = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "        words = splits[0].lower().split()\n",
    "        count = splits[1]\n",
    "\n",
    "        H = {}\n",
    "        for subset in itertools.combinations(sorted(set(words)), 2):\n",
    "            \n",
    "            # Logic from slack discussion, with Sharmila and Kyle: the stripes are assymentric\n",
    "            # If a given word is a valid word, then we build a stripe for the other word and add\n",
    "            # its co-ocurrence to the valid word. If both words are valid, only then we add\n",
    "            # to stripes in a symmetric way\n",
    "            \n",
    "            if subset[1] in self.valid_words:\n",
    "\n",
    "                # Process combinations in sorted order, i.e. \"hello\",\"tomorrow\"\n",
    "                if subset[0] not in H.keys():\n",
    "                    H[subset[0]] = {}\n",
    "                    H[subset[0]][subset[1]] = count \n",
    "                elif subset[1] not in H[subset[0]]:\n",
    "                    H[subset[0]][subset[1]] = count\n",
    "                else:\n",
    "                    H[subset[0]][subset[1]] += count\n",
    "\n",
    "            if subset[0] in self.valid_words:\n",
    "                # Obtain combinations in reverse order\n",
    "                if subset[1] not in H.keys():\n",
    "                    H[subset[1]] = {}\n",
    "                    H[subset[1]][subset[0]] = count \n",
    "                elif subset[0] not in H[subset[1]]:\n",
    "                    H[subset[1]][subset[0]] = count\n",
    "                else:\n",
    "                    H[subset[1]][subset[0]] += count\n",
    "                    \n",
    "        for key in H.keys():\n",
    "            yield key, H[key]\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        \n",
    "        counter = {}\n",
    "\n",
    "        for value in values:\n",
    "            \n",
    "            for k, v in value.iteritems():\n",
    "                if k in counter:\n",
    "                    counter[k] += int(v)\n",
    "                else:\n",
    "                    counter[k] = int(v)\n",
    "        \n",
    "        yield key, counter\n",
    "\n",
    "  #END SUDENT CODE531_STRIPES\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    stripes.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `stripes5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/frequencies5_5.nhaas.20170620.014015.768683\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.014015.768683/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7574727151082325260.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1497906899862_0175\n",
      "  Submitted application application_1497906899862_0175\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0175/\n",
      "  Running job: job_1497906899862_0175\n",
      "  Job job_1497906899862_0175 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 63%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0175 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.014015.768683/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4158739\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=39013260\n",
      "\t\tFILE: Number of bytes written=138207096\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156101116\n",
      "\t\tHDFS: Number of bytes written=4158739\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=35726502912\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=327224320\n",
      "\t\tTotal time spent by all map tasks (ms)=23259442\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=69778326\n",
      "\t\tTotal time spent by all reduce tasks (ms)=127822\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=639110\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=23259442\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=127822\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=14777410\n",
      "\t\tCombine input records=293411330\n",
      "\t\tCombine output records=6822745\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=100562\n",
      "\t\tInput split bytes=32000\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=3430141090\n",
      "\t\tMap output materialized bytes=73800744\n",
      "\t\tMap output records=293411330\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154707279872\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=6822745\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=73800744\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13645490\n",
      "\t\tTotal committed heap usage (bytes)=298742448128\n",
      "\t\tVirtual memory (bytes) snapshot=421117415424\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5077579050119969266.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1497906899862_0178\n",
      "  Submitted application application_1497906899862_0178\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0178/\n",
      "  Running job: job_1497906899862_0178\n",
      "  Job job_1497906899862_0178 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0178 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.014015.768683/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4176522\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=17944\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2953963\n",
      "\t\tFILE: Number of bytes written=6321853\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4176884\n",
      "\t\tHDFS: Number of bytes written=17944\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=21602304\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=24668160\n",
      "\t\tTotal time spent by all map tasks (ms)=14064\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=42192\n",
      "\t\tTotal time spent by all reduce tasks (ms)=9636\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=48180\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=14064\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=9636\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=13180\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=260\n",
      "\t\tInput split bytes=362\n",
      "\t\tMap input records=269339\n",
      "\t\tMap output bytes=4428078\n",
      "\t\tMap output materialized bytes=2969260\n",
      "\t\tMap output records=269339\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1958662144\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=269339\n",
      "\t\tReduce output records=1000\n",
      "\t\tReduce shuffle bytes=2969260\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538678\n",
      "\t\tTotal committed heap usage (bytes)=5201461248\n",
      "\t\tVirtual memory (bytes) snapshot=7776161792\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.014015.768683/output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/frequencies5_5.nhaas.20170620.014015.768683...\n",
      "Removing temp directory /tmp/frequencies5_5.nhaas.20170620.014015.768683...\n",
      "WARNING:root:Elapsed time: 574.018336058 seconds\n",
      "    In minutes: 9.56697226763 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r stripes5.5\n",
    "!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies 5_5 on Full Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: 574.02 seconds_\n",
    "\n",
    "* _Run time: 9.57 minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: 4176522_\n",
    "\n",
    "* _Bytes Written: 17944_\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: 2_\n",
    "\n",
    "* _Number of Reducers: 1_\n",
    "\n",
    "* _CPU time spent: 13180_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: stripes5.5: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat stripes5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing index5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile index5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class index(MRJob):\n",
    "    \n",
    "    #START SUDENT CODE531_INV_INDEX\n",
    "  \n",
    "    def mapper(self, _, line):\n",
    "        key, stripeJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        stripe = json.loads(stripeJson)\n",
    "        \n",
    "        for k, v in stripe.iteritems():\n",
    "            yield k, [key, len(stripe)]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "\n",
    "        table = {}\n",
    "        for value in values:\n",
    "            table[value[0]] = value[1]\n",
    "            \n",
    "        yield key, table\n",
    "        \n",
    "    #END SUDENT CODE531_INV_INDEX\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    index.run() \n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `index5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Traceback (most recent call last):\n",
      "  File \"index5_5.py\", line 43, in <module>\n",
      "    index.run() \n",
      "  File \"/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/mrjob/job.py\", line 429, in run\n",
      "    mr_job.execute()\n",
      "  File \"/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/mrjob/job.py\", line 447, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/mrjob/launch.py\", line 158, in execute\n",
      "    self.run_job()\n",
      "  File \"/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/mrjob/launch.py\", line 228, in run_job\n",
      "    runner.run()\n",
      "  File \"/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/mrjob/runner.py\", line 481, in run\n",
      "    self._run()\n",
      "  File \"/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/mrjob/hadoop.py\", line 332, in _run\n",
      "    self._check_input_exists()\n",
      "  File \"/home/nhaas/.conda/envs/my_env/lib/python2.7/site-packages/mrjob/hadoop.py\", line 348, in _check_input_exists\n",
      "    'Input path %s does not exist!' % (path,))\n",
      "AssertionError: Input path stripes5.5 does not exist!\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index 5_5 on Stripes5.5 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat index5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing similarity5_5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity5_5.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "#import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import time\n",
    "import logging\n",
    "\n",
    "class similarity(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_SIMILARITY\n",
    "\n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        key, valuesJson = line.strip().split('\\t')\n",
    "        key = key.strip(\"\\\"\")\n",
    "        values = json.loads(valuesJson)\n",
    "\n",
    "        for pair in itertools.combinations(sorted(set(values)), 2):\n",
    "            yield pair, [values[pair[0]], values[pair[1]]]\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        intersection = 0\n",
    "        count1 = None\n",
    "        count2 = None\n",
    "        \n",
    "        cosine = 0.0\n",
    "        \n",
    "        # Iterate through the values\n",
    "        for value in values:\n",
    "            # Jaccard, get counts for the intersection, and for each set\n",
    "            intersection += 1\n",
    "            if count1 == None:\n",
    "                count1 = value[0]\n",
    "                count2 = value[1]\n",
    "        \n",
    "            # Cosine\n",
    "            a = 1 / math.sqrt(value[0])\n",
    "            b = 1 / math.sqrt(value[1])\n",
    "            cosine += a * b\n",
    "            \n",
    "        jaccard = float(intersection) / float(count1 + count2 - intersection)\n",
    "        \n",
    "        overlap_coefficient = float(intersection) / min(count1, count2)\n",
    "        \n",
    "        dice_coefficient = float(2 * intersection) / (count1 + count2)\n",
    "        \n",
    "        average = (cosine + jaccard + overlap_coefficient + dice_coefficient) / 4.0\n",
    "        \n",
    "        yield average, [key[0] + ' - ' + key[1], cosine, jaccard, overlap_coefficient, dice_coefficient, average]\n",
    "    \n",
    "    \n",
    "    def max_reducer(self, average, records):\n",
    "        for record in records:\n",
    "            yield average, record\n",
    "\n",
    "    def steps(self):\n",
    "        \n",
    "        custom_jobconf = {\n",
    "            'stream.num.map.output.key.fields':'2',\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "            'mapred.reduce.tasks': '1'\n",
    "        }\n",
    "\n",
    "        return [\n",
    "                MRStep(mapper=self.mapper,\n",
    "                    reducer=self.reducer),\n",
    "                MRStep(jobconf=custom_jobconf,\n",
    "                       reducer=self.max_reducer)\n",
    "                 ]\n",
    "    \n",
    "    #END SUDENT CODE531_SIMILARITY\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    similarity.run()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    mins = elapsed_time/float(60)\n",
    "    a = \"\"\"Elapsed time: %s seconds\n",
    "    In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "    logging.warning(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `similarity5.5': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity5_5.nhaas.20170620.014955.280458\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/nhaas/tmp/mrjob/similarity5_5.nhaas.20170620.014955.280458/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob9135377036989685515.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:1\n",
      "  Submitting tokens for job: job_1497906899862_0179\n",
      "  Submitted application application_1497906899862_0179\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0179/\n",
      "  Running job: job_1497906899862_0179\n",
      "  Job job_1497906899862_0179 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0179 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity5_5.nhaas.20170620.014955.280458/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=20\n",
      "\t\tFILE: Number of bytes written=265175\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=166\n",
      "\t\tHDFS: Number of bytes written=0\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=9830400\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9152000\n",
      "\t\tTotal time spent by all map tasks (ms)=6400\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=19200\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3575\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17875\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6400\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3575\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1350\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=62\n",
      "\t\tInput split bytes=166\n",
      "\t\tMap input records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tMap output records=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tPhysical memory (bytes) snapshot=1106206720\n",
      "\t\tReduce input groups=0\n",
      "\t\tReduce input records=0\n",
      "\t\tReduce output records=0\n",
      "\t\tReduce shuffle bytes=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tSpilled Records=0\n",
      "\t\tTotal committed heap usage (bytes)=3651141632\n",
      "\t\tVirtual memory (bytes) snapshot=5567410176\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.reduce.tasks: mapreduce.job.reduces\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob366098270383854399.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:1\n",
      "  Submitting tokens for job: job_1497906899862_0180\n",
      "  Submitted application application_1497906899862_0180\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1497906899862_0180/\n",
      "  Running job: job_1497906899862_0180\n",
      "  Job job_1497906899862_0180 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1497906899862_0180 completed successfully\n",
      "  Output directory: hdfs:///user/nhaas/tmp/mrjob/similarity5_5.nhaas.20170620.014955.280458/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=20\n",
      "\t\tFILE: Number of bytes written=265741\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=179\n",
      "\t\tHDFS: Number of bytes written=0\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=9318912\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8890880\n",
      "\t\tTotal time spent by all map tasks (ms)=6067\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=18201\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3473\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17365\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6067\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3473\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=1320\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=80\n",
      "\t\tInput split bytes=179\n",
      "\t\tMap input records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=16\n",
      "\t\tMap output records=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tPhysical memory (bytes) snapshot=1096818688\n",
      "\t\tReduce input groups=0\n",
      "\t\tReduce input records=0\n",
      "\t\tReduce output records=0\n",
      "\t\tReduce shuffle bytes=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tSpilled Records=0\n",
      "\t\tTotal committed heap usage (bytes)=3651141632\n",
      "\t\tVirtual memory (bytes) snapshot=5563936768\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/nhaas/tmp/mrjob/similarity5_5.nhaas.20170620.014955.280458/output...\n",
      "Removing HDFS temp directory hdfs:///user/nhaas/tmp/mrjob/similarity5_5.nhaas.20170620.014955.280458...\n",
      "Removing temp directory /tmp/similarity5_5.nhaas.20170620.014955.280458...\n",
      "WARNING:root:Elapsed time: 86.2703969479 seconds\n",
      "    In minutes: 1.43783994913 mins\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity 5_5 on Index 5.5 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named nltk",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-fec50ed38a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named nltk"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT CODE 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
    "(From the entire data set)\n",
    "\n",
    "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "                   cons - pros |       0.894427 |       0.800000 |       1.000000 |       0.888889 |       0.895829\n",
    "            forties - twenties |       0.816497 |       0.666667 |       1.000000 |       0.800000 |       0.820791\n",
    "                    own - time |       0.809510 |       0.670563 |       0.921168 |       0.802799 |       0.801010\n",
    "                 little - time |       0.784197 |       0.630621 |       0.926101 |       0.773473 |       0.778598\n",
    "                  found - time |       0.783434 |       0.636364 |       0.883788 |       0.777778 |       0.770341\n",
    "                 nova - scotia |       0.774597 |       0.600000 |       1.000000 |       0.750000 |       0.781149\n",
    "                   hong - kong |       0.769800 |       0.615385 |       0.888889 |       0.761905 |       0.758995\n",
    "                   life - time |       0.769666 |       0.608789 |       0.925081 |       0.756829 |       0.765091\n",
    "                  time - world |       0.755476 |       0.585049 |       0.937500 |       0.738209 |       0.754058\n",
    "                  means - time |       0.752181 |       0.587117 |       0.902597 |       0.739854 |       0.745437\n",
    "                   form - time |       0.749943 |       0.588418 |       0.876733 |       0.740885 |       0.738995\n",
    "       infarction - myocardial |       0.748331 |       0.560000 |       1.000000 |       0.717949 |       0.756570\n",
    "                 people - time |       0.745788 |       0.573577 |       0.923875 |       0.729010 |       0.743063\n",
    "                 angeles - los |       0.745499 |       0.586207 |       0.850000 |       0.739130 |       0.730209\n",
    "                  little - own |       0.739343 |       0.585834 |       0.767296 |       0.738834 |       0.707827\n",
    "                    life - own |       0.737053 |       0.582217 |       0.778502 |       0.735951 |       0.708430\n",
    "          anterior - posterior |       0.733388 |       0.576471 |       0.790323 |       0.731343 |       0.707881\n",
    "                  power - time |       0.719611 |       0.533623 |       0.933586 |       0.695898 |       0.720680\n",
    "              dearly - install |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
    "                   found - own |       0.704802 |       0.544134 |       0.710949 |       0.704776 |       0.666165\n",
    "\n",
    "           arrival - essential |       0.008258 |       0.004098 |       0.009615 |       0.008163 |       0.007534\n",
    "         governments - surface |       0.008251 |       0.003534 |       0.014706 |       0.007042 |       0.008383\n",
    "                king - lesions |       0.008178 |       0.003106 |       0.017857 |       0.006192 |       0.008833\n",
    "              clinical - stood |       0.008178 |       0.003831 |       0.011905 |       0.007634 |       0.007887\n",
    "               till - validity |       0.008172 |       0.003367 |       0.015625 |       0.006711 |       0.008469\n",
    "            evidence - started |       0.008159 |       0.003802 |       0.012048 |       0.007576 |       0.007896\n",
    "               forces - record |       0.008152 |       0.003876 |       0.011364 |       0.007722 |       0.007778\n",
    "               primary - stone |       0.008146 |       0.004065 |       0.009091 |       0.008097 |       0.007350\n",
    "             beneath - federal |       0.008134 |       0.004082 |       0.008403 |       0.008130 |       0.007187\n",
    "                factors - rose |       0.008113 |       0.004032 |       0.009346 |       0.008032 |       0.007381\n",
    "           evening - functions |       0.008069 |       0.004049 |       0.008333 |       0.008065 |       0.007129\n",
    "                   bone - told |       0.008061 |       0.003704 |       0.012346 |       0.007380 |       0.007873\n",
    "             building - occurs |       0.008002 |       0.003891 |       0.010309 |       0.007752 |       0.007489\n",
    "                 company - fig |       0.007913 |       0.003257 |       0.015152 |       0.006494 |       0.008204\n",
    "               chronic - north |       0.007803 |       0.003268 |       0.014493 |       0.006515 |       0.008020\n",
    "             evaluation - king |       0.007650 |       0.003030 |       0.015625 |       0.006042 |       0.008087\n",
    "             resulting - stood |       0.007650 |       0.003663 |       0.010417 |       0.007299 |       0.007257\n",
    "                 agent - round |       0.007515 |       0.003289 |       0.012821 |       0.006557 |       0.007546\n",
    "         afterwards - analysis |       0.007387 |       0.003521 |       0.010204 |       0.007018 |       0.007032\n",
    "            posterior - spirit |       0.007156 |       0.002660 |       0.016129 |       0.005305 |       0.007812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.6  <a name=\"5.6\"></a> Evaluation of synonyms that your discovered\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "\n",
    "In this part of the assignment you will evaluate the success of you synonym detector (developed in response to HW5.4).\n",
    "Take the top 1,000 closest/most similar/correlative pairs of words as determined by your measure in HW5.4, and use the synonyms function in the accompanying python code:\n",
    "\n",
    "nltk_synonyms.py\n",
    "\n",
    "Note: This will require installing the python nltk package:\n",
    "\n",
    "http://www.nltk.org/install.html\n",
    "\n",
    "and downloading its data with nltk.download().\n",
    "\n",
    "For each (word1,word2) pair, check to see if word1 is in the list, \n",
    "synonyms(word2), and vice-versa. If one of the two is a synonym of the other, \n",
    "then consider this pair a 'hit', and then report the precision, recall, and F1 measure  of \n",
    "your detector across your 1,000 best guesses. Report the macro averages of these measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate performance measures:\n",
    "$$Precision (P) = \\frac{TP}{TP + FP} $$  \n",
    "$$Recall (R) = \\frac{TP}{TP + FN} $$  \n",
    "$$F1 = \\frac{2 * ( precision * recall )}{precision + recall}$$\n",
    "\n",
    "\n",
    "We calculate Precision by counting the number of hits and dividing by the number of occurances in our top1000 (opportunities)   \n",
    "We calculate Recall by counting the number of hits, and dividing by the number of synonyms in wordnet (syns)\n",
    "\n",
    "\n",
    "Other diagnostic measures not implemented here:  https://en.wikipedia.org/wiki/F1_score#Diagnostic_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Performance measures '''\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "hits = []\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "TOTAL = 0\n",
    "flag = False # so we don't double count, but at the same time don't miss hits\n",
    "start_time = time.time()\n",
    "top1000sims = []\n",
    "with open(\"sims2/top1000sims\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        top1000sims.append(lisst)\n",
    "    \n",
    "\n",
    "measures = {}\n",
    "not_in_wordnet = []\n",
    "\n",
    "for line in top1000sims:\n",
    "    TOTAL += 1\n",
    "\n",
    "    pair = line[0]\n",
    "    words = pair.split(\" - \")\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in measures:\n",
    "            measures[word] = {\"syns\":0,\"opps\": 0,\"hits\":0}\n",
    "        measures[word][\"opps\"] += 1 \n",
    "    \n",
    "    syns0 = synonyms(words[0])\n",
    "    measures[words[1]][\"syns\"] = len(syns0)\n",
    "    if len(syns0) == 0:\n",
    "        not_in_wordnet.append(words[0])\n",
    "        \n",
    "    if words[1] in syns0:\n",
    "        TP += 1\n",
    "        hits.append(line)\n",
    "        flag = True\n",
    "        measures[words[1]][\"hits\"] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    syns1 = synonyms(words[1]) \n",
    "    measures[words[0]][\"syns\"] = len(syns1)\n",
    "    if len(syns1) == 0:\n",
    "        not_in_wordnet.append(words[1])\n",
    "\n",
    "    if words[0] in syns1:\n",
    "        if flag == False:\n",
    "            TP += 1\n",
    "            hits.append(line)\n",
    "            measures[words[0]][\"hits\"] += 1\n",
    "            \n",
    "    flag = False    \n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for key in measures:\n",
    "    p,r,f = 0,0,0\n",
    "    if measures[key][\"hits\"] > 0 and measures[key][\"syns\"] > 0:\n",
    "        p = measures[key][\"hits\"]/measures[key][\"opps\"]\n",
    "        r = measures[key][\"hits\"]/measures[key][\"syns\"]\n",
    "        f = 2 * (p*r)/(p+r)\n",
    "    \n",
    "    # For calculating measures, only take into account words that have synonyms in wordnet\n",
    "    if measures[key][\"syns\"] > 0:\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f)\n",
    "\n",
    "    \n",
    "# Take the mean of each measure    \n",
    "print \"\"*110    \n",
    "print \"Number of Hits:\",TP, \"out of top\",TOTAL\n",
    "print \"Number of words without synonyms:\",len(not_in_wordnet)\n",
    "print \"\"*110 \n",
    "print \"Precision\\t\", np.mean(precision)\n",
    "print \"Recall\\t\\t\", np.mean(recall)\n",
    "print \"F1\\t\\t\", np.mean(f1)\n",
    "print \"\"*110  \n",
    "\n",
    "print \"Words without synonyms:\"\n",
    "print \"-\"*100\n",
    "\n",
    "for word in not_in_wordnet:\n",
    "    print synonyms(word),word\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "mins = elapsed_time/float(60)\n",
    "a = \"\"\"Elapsed time: %s seconds\n",
    "In minutes: %s mins\"\"\" % (str(elapsed_time), str(mins))\n",
    "logging.warning(a)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Number of Hits: 31 out of top 1000\n",
    "Number of words without synonyms: 67\n",
    "\n",
    "Precision\t0.0280214404967\n",
    "Recall\t\t0.0178598869579\n",
    "F1\t\t0.013965517619\n",
    "\n",
    "Words without synonyms:\n",
    "----------------------------------------------------------------------------------------------------\n",
    "[] scotia\n",
    "[] hong\n",
    "[] kong\n",
    "[] angeles\n",
    "[] los\n",
    "[] nor\n",
    "[] themselves\n",
    "[] \n",
    "......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.7  <a name=\"5.7\"></a> OPTIONAL: using different vocabulary subsets\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "\n",
    "Repeat HW5 using vocabulary words ranked from 8001,-10,000;  7001,-10,000; 6001,-10,000; 5001,-10,000; 3001,-10,000; and 1001,-10,000;\n",
    "Dont forget to report you Cluster configuration.\n",
    "\n",
    "Generate the following graphs:\n",
    "-- vocabulary size (X-Axis) versus CPU time for indexing\n",
    "-- vocabulary size (X-Axis) versus number of pairs processed\n",
    "-- vocabulary size (X-Axis) versus F1 measure, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 8001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 8001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 7001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 7001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Vocab Subset 7000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "\n",
    "### Stripes on Vocab Subset 7000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Index on Vocab Subset 7000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Similarity on Vocab Subset 7000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 6001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 6001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Vocab Subset 6000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "\n",
    "### Stripes on Vocab Subset 6000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Index on Vocab Subset 6000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Similarity on Vocab Subset 6000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 5001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 5001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Vocab Subset 5000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "\n",
    "### Stripes on Vocab Subset 5000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Index on Vocab Subset 5000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Similarity on Vocab Subset 5000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 4001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 4001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Vocab Subset 4000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "\n",
    "### Stripes on Vocab Subset 4000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Index on Vocab Subset 4000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Similarity on Vocab Subset 4000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 3001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 3001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Vocab Subset 3000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "\n",
    "### Stripes on Vocab Subset 3000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Index on Vocab Subset 3000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Similarity on Vocab Subset 3000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 2001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 2001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Vocab Subset 2000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "\n",
    "### Stripes on Vocab Subset 2000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Index on Vocab Subset 2000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Similarity on Vocab Subset 2000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7: Vocabulary subset 1001-10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r frequencies5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5\n",
    "!python frequencies5_5.py --min_rank 1001 --max_rank 10000 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > frequencies5.5\n",
    "\n",
    "!hdfs dfs -rm -r stripes5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python stripes5_5.py --file=frequencies5.5 -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered.txt > stripes5.5\n",
    "\n",
    "!hdfs dfs -rm -r index5.5\n",
    "!python index5_5.py -r hadoop stripes5.5 > index5.5\n",
    "\n",
    "!hdfs dfs -rm -r similarity5.5\n",
    "#!python frequencies5_5.py -r hadoop hdfs:///user/cendylin/filtered-5Grams/ > frequencies5.5'\n",
    "!python similarity5_5.py -r hadoop index5.5 > similarity5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies on Vocab Subset 1000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "\n",
    "### Stripes on Vocab Subset 1000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Index on Vocab Subset 1000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _\n",
    "\n",
    "### Similarity on Vocab Subset 1000-10000 Set Statistics:\n",
    "\n",
    "#### Time\n",
    "* _Run time: - seconds_\n",
    "\n",
    "* _Run time: - minutes_\n",
    "\n",
    "#### Input/Output statistics\n",
    "* _Bytes Read: - _\n",
    "\n",
    "* _Bytes Written: - _\n",
    "\n",
    "#### Cluster Resources\n",
    "* _Number of Mappers: - _\n",
    "\n",
    "* _Number of Reducers: - _\n",
    "\n",
    "* _CPU time spent: - _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sortedSims = []\n",
    "with open(\"similarity5.5\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        line = line.strip()\n",
    "        avg,lisst = line.split(\"\\t\")\n",
    "        lisst = json.loads(lisst)\n",
    "        lisst.append(avg)\n",
    "        sortedSims.append(lisst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir sims2\n",
    "!head -1000 similarity5.5 > sims2/top1000sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "for stripe in sortedSims[:20]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )\n",
    "\n",
    "print ''*117\n",
    "\n",
    "for stripe in sortedSims[-20:]:\n",
    "    print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "        stripe[0], float(stripe[1]), float(stripe[2]), float(stripe[3]), float(stripe[4]), float(stripe[5]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.8  <a name=\"5.8\"></a> OPTIONAL: filter stopwords\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> from nltk.corpus import stopwords\n",
    ">> stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.9 <a name=\"5.9\"></a> OPTIONAL \n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "There are many good ways to build our synonym detectors, so for this optional homework, \n",
    "measure co-occurrence by (left/right/all) consecutive words only, \n",
    "or make stripes according to word co-occurrences with the accompanying \n",
    "2-, 3-, or 4-grams (note here that your output will no longer \n",
    "be interpretable as a network) inside of the 5-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.10 <a name=\"5.10\"></a> OPTIONAL \n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Once again, benchmark your top 10,000 associations (as in 5.5), this time for your\n",
    "results from 5.6. Has your detector improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "511px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
